---
title: "Glossary 名词解释"
---

> Glossary is important and irrelevant at the same time.

> **NOTE**: 以下概念是我学习过程中遇到并且你需要掌握的, 其它文章中我将不会对以下名词进行解释.


## General Terms

- **CFU**: Custom Function Unit (自定义功能单元). 为 ML 某些耗时的计算 (如卷积、矩阵乘法、位操作等) 定制的指令加速硬件模块.
    - 一旦主处理器执行到特定的 CFU 指令，就会将数据发送给 CFU 处理，然后 CFU 返回结果.
    - **FPU**: Floating Point Unit (浮点运算单元), 是 CPU 中专门处理浮点数运算的硬件组件.

- **Git LFS**: Git Large File Storage. 解决了 github 不能上传大文件的问题. 使用:

    ```bash
    sudo apt-get install git-lfs
    git lfs install # 在项目目录中初始化 Git LFS
    git lfs pull # 下载实际文件
    ```

    然后原来的文件的格式就会从文本格式变为真正的 ZIP 文件, 可以通过下面的命令查看:

    ```bash
    file test.zip # 返回 
    ```

## FPGA Terms

### General

- **TfLM**: TensorFlow Lite for Microcontrollers. 
    - **PDTI8**: Person DeTection Int 8

- **Gateware**: 用软件编写的硬件电路. (既不是 Software, 也不是 Hardware).

- **HPS**: High Performance System. 
    - `PLATFORMS=common_soc sim hps`, 三个平台. `common_soc` 指标准的 FPGA 开发平台; `sim` 指用 Verilator 进行软件仿真.

- **SoC (System on Chip) FPGA 片上系统**: 比如 ZYNQ 有 PL 和 PS, **一块硅芯片** 就可以实现整个系统的功能 (而不是要组合多个芯片 (Chiplet)). 有时 Chiplets 组成的系统也叫 SoC, 但严格来说 SoC 是指单芯片系统. 

- **ACAP (Adaptive Compute Acceleration Platform)**: 集成了专用 AI 引擎／DSP阵列、Network-on-chip (NoC)、高带宽存储接口 (如 HBM) 等异构硬件资源 @sali2025realtimefpgabased, 如 Xilinx Versal 系列.

- **IP Core**: Intellectual Property Core. 由一方 (开发者或公司) 设计，并通过许可授权给其他设计者使用。常见的 IP 核包括 CPU 内核、以太网控制器、内存控制器等.
    - **Soft IP**: 软核
    - **Hard IP**: 硬核


- **`.vcd`, `fst`**: 波形文件格式, 后者占空间更小, 但只受 GTKWave 支持 @Simulation_Time._Putting_2025_oscc.

### Interface

- **PMOD (Peripheral Module) 接口**: 一组 2*6 排针的引脚 PMOD. 定义了电源、地线、以及最多 8 条可用于通信的信号线. PMOD模块通常通过 SPI、I2C 或 GPIO (通用数字输入输出) 与主控通信. 你可以买到很多支持 PMOD 的模块, 如传感器、显示屏、存储器等.

- **JTAG 接口**: 一种用于调试和编程的标准接口.

- **AXI (Advanced eXtensible Interface) 接口**: CPU 与外设 (内存控制器, DMA, CFU, IP 核) 之间的通信协议. 
    - 比如 ZYNQ 的 **PS (Processing System)** 和 **PL (Programmable Logic)** 之间的通信就是通过 AXI 接口 (见 [FPGA 原理速成](../cc-fpga/cc-fpga.qmd#sec-ps-structure)).

### ZYNQ

- **核心商业模式**: 
    - **IP 提供商**: 设计 IP 核并授权给芯片设计制造商使用. E.g., ARM (CPU 内核设计)
    - **芯片设计制造商**: 购买 IP 核并设计和生产关键芯片. E.g., Xilinx (被 AMD 收购), ST (STM32 核心芯片的制造商).
    - **开发板制造商**: 从芯片设计制造商处采购芯片, 并设计供电电路、时钟电路、将方形黑色的芯片底部的引脚引出接入各种物理接口、设计 PCB 等, 最终生产出开发板. E.g., Alinx, 正点原子, Digilent.

- **命名规则**
    - E.g., ZYNQ XC7Z010 CLG400ABX2021 D6168711A, XC7: 7 系列 (Xilinx Corporation), Z: ZYNQ, 010: 逻辑资源规模 (越小越少), CLG: 封装类型 (Chip-Scale Lead-Free BGA (Ball Grid Array)), 400: 引脚数, ABX: 温度、性能等级, 2021: 生产年份, D6168711A: 可理解为序列号.
    - ZYNQ 7010 SoCs 包括 XC7Z010 等很多型号.

:::{.column-margin}
![ZYNQ 7010 实物图: Xilinx 与 Alinx 公司分别负责的部分.](zynq-7010-board.png)
:::

- **APU (Application Processing Unit)**: ZYNQ PS 内部的一个双核 ARM Cortex-A9 CPU. (就是 CPU, 见 [FPGA 原理速成](../cc-fpga/cc-fpga.qmd#sec-ps-structure))

- **MIO (Multiplexed I/O)**: ZYNQ PS 黑色芯片里面有多种外设: SPI, IIC, CAN, UART, etc. 比如 UART 主要涉及 TX 和 RX 两类信号, 这两类信号需要通过 MIO 与用户交互. 但是 BGA 封装出来的引脚很少 (XC7 只有 54 根), 需要进行复用.
    - **EMIO (Extended MIO)**: 先要通过 PL 再与用户交互.

- **GIC (Generic Interrupt Controller)**: 通用中断控制器, 收集外设、PL 发来的中断请求, 按优先级分配给 APU 中的两个核. 相当于 STM32 里面的 NVIC (Nested Vectored Interrupt Controller), 只不过 NVIC 只需要给到一个核.

### File formats

- **`.pcf` 文件**: Physical Constraints File. `.pcf` 文件告诉工具：Verilog 中的某个逻辑信号，物理上应该接到 FPGA 的哪个 pin. 比如:

    ```txt
    set_io D1 B5
    ```

    表示把 `D1` (在 `.v` 文件中定义的) 信号连接到 FPGA 的 B5 引脚.

    - **`.xdc` 文件**: Xilinx Design Constraints File (Vivado 工具使用的约束文件, a.k.a., Master Constraints File 主约束文件). [Arty 35T xdc 文件](https://raw.githubusercontent.com/Digilent/digilent-xdc/master/Arty-A7-35-Master.xdc)

### HDL

- **HLS**: High-Level Synthesis. 用 C/C++ 等高级语言来写硬件电路设计.

    - **Scala (Scalable language)**: 一种专门生成其它 DSL (Domain Specific Language) 的语言. 生成的语言包括:
        - **SpinalHDL**: 一种 Hardware Description Language (HDL). 可用来生成更底层的 Verilog 代码. 
            - **[VexRiscv Soft CPU](https://github.com/SpinalHDL/VexRiscv)**: 用 SpinalHDL 写的一个 高度可配置的 RISC-V soft CPU 内核 (soft 的意思就是 CPU 不是硬件焊死的 ("hard CPU") , 而是部署在 FPGA 上可以改变结构的).
        - **Chisel**: 另一种 HDL. 
        - **Scalac**: Scala 编译器.
        - **sbt**: Scala Build导出 Tool. 配置依赖、插件和调用 scalac. 会在指定目录下面生成 `.v` 或 `.sv` 文件.
            - **.fir**: FIRRTL (Flexible Intermediate Representation for RTL) 文件, 一种用于硬件设计的中间表示 (加上 `--dump-fir` 选项即可, `dump` 一般表示「导出」).
        - **Mill**: 跟 sbt 类似, 但更轻量.
        

    - **Amaranth**: 一个 Python 库, 也是用于硬件描述和设计. 可生成 Verilog 代码.


- **RTL (Register Transfer Level)**: 通俗说就是 verilog 代码. 可视为芯片设计的前端.

    ![](design-level.png){#fig-design-level width=80%}



### FPGA Principles

- **PAR**： Place and Route. 布局布线. 


### FPGA Structure 结构

- **BLE, CLB (Slice, LAB, ALM), SB**: 见 [FPGA 原理速成](../cc-fpga/cc-fpga.qmd#sec-pl-structure).

- **LUT (Look-Up Table)**: 查找表. 所有写 `Verilog` 的行为一般都会被综合成 LUT + FF 的结构.

- **DSP (Digital Signal Processing) Block**: FPGA 上专门进行数值运算 (乘加) 的硬件模块 (是卷积、矩阵乘法核心).
    - **LUT-based DSP**: 与 DSP Block 有本质的区别, 综合器会把它看成 LUT + FF 结构, 而不是调用板子上的 DSP Block 硬件资源.

### Verification 验证

> 验证是芯片设计很重要的一环, 下面将简要介绍 Verification 的一些概念, 遵循认识论原则.

- **DUT**: Device Under Test. 被测试的模块.

- **TB (Testbench)**: 狭义来说就是用 `verilog` 写的测试代码 (`initial begin` 之类的). 但写过都知道有以下缺点:
    - 基本上只能验证模块的功能正确性.
    - 输入什么信号都要自己写, 很费时, 而且缺乏随机性.

- **UVM (Universal Verification Methodology)**: 验证方法学.

## Open Source Tools

> 该项目重度使用了以下开源项目, FPGA 开源是一个很大的工程, 感谢所有开源者!

- [**verilator**](https://github.com/verilator/verilator): 将 verilog 代码变成 C++ 代码, 然后编译并运行在 CPU 上进行**仿真**, 模拟出时钟、寄存器逻辑、外设交互等行为.

    ```bash
    verilator -cc blink.v # 生成 obj_dir/ 其中含有转换好的 C++ 代码
    ```

- [**iverilog (Icarus Verilog)**](https://github.com/steveicarus/iverilog): 也是仿真 (但不输出 C 代码):

    ```bash
    iverilog -o blink.vvp blink.v blink_tb.v
    # 生成 vcd 文件可配合 GTKWave 查看波形
    vvp blink.vvp
    ```

- [**openFPGALoader**](https://github.com/trabucayre/openFPGALoader): 用于将比特流烧录到 FPGA (但不能调试).

    ```bash
    # 示例：
    openFPGALoader -b arty arty_bitstream.bit      # SRAM 加载
    openFPGALoader -b arty -f arty_bitstream.bit   # 写入 flash
    ```

- [**openocd**](https://github.com/openocd-org/openocd): Open On-Chip Debugger. 用于调试 FPGA 的工具. 支持 JTAG 接口.

- 三个端到端的工具链:

    - **Vivado**: IDE, 闭源.

    - [**yosysHQ (Yosys Open SYnthesis Suite Headquarters)**](https://github.com/YosysHQ): yyds!! 一个开源的 EDA 工具链. 子项目包括:
        - [**icestorm**](https://github.com/YosysHQ/icestorm): 用于针对 Lattice iCE40 FPGA 实现完全的端到端开源流程, 从 Verilog 到 bitstream, 再烧写到 FPGA 板卡上. 以下每一个命令都是一个单独的 repo!!

            ```bash
            # yosys 综合 (将 verilog 转换为网表 .json)
            yosys -p 'synth_ice40 -top blink -json blink.json' blink.v
            # nextpnr 布局布线 (生成 bitstream 的中间文件 .asc)
            nextpnr-ice40 --up5k --json blink.json --pcf blink.pcf --asc blink.asc
            # icepack 打包 (生成 bitstream .bin)
            icepack blink.asc blink.bin
            # icesprog 烧写 (将 bitstream 写入 FPGA)
            sudo icesprog blink.bin
            ```

    - [**F4PGA**](https://github.com/chipsalliance/f4pga): 以前叫 `Symbiflow`, 旨在为多家 FPGA 供应商 (Xilinx 7 系列、Lattice iCE40/ECP5、QuickLogic EOS S3 等) 提供统一、功能完备、可扩展且无需专有软件的端到端开发流程.
        - 里面大量使用了 `YosysHQ` 的工具.

- [**SpinalHDL**](https://github.com/SpinalHDL): 一个基于 Scala 的硬件描述语言 (HDL), 用于生成 Verilog 代码. SpinalHDL 提供了更高级的抽象和更强大的功能, 使得硬件设计更加灵活和可扩展.
    - [**VexRiscv**](https://github.com/SpinalHDL/VexRiscv): 

- [**Litex**](https://github.com/enjoy-digital/litex): 支持用 Python 脚本拼装出完整的 SoC.

## EDA Terms {#sec-eda-terms}

- **AIEDA (MLDA/EDI/EDA2.0)**: 利用 AI 来辅助 EDA 设计流程.

- **Netlist 网表**: 一个 Graph, 描述了电路用了哪些元件和它们之间的连接. 
    - Gate-level 门级网表: 比如用 `yosys` 生成的 `.json` 文件.
    - Transistor-level 晶体管级网表: `.spice`, `.cir`.

- **Fan-in 扇入**: 连接到 pin $v_i \in V$ 的 pin 集合称为 $v_i$ 的 fan-in, 记为 $\mathcal{F}(v_i)$ @liao_2023_dreamplace.
    - **Fan-out 扇出** @fig-fan-in-out.

:::{.column-margin}
![$v_i$ 节点有 $3$ 个 Fan-in 节点 和 $2$ 个 Fan-out 节点](fan-in-out.png){#fig-fan-in-out}
:::

- **LEF (Library Exchange Format)**: 描述 cell 的物理信息 (尺寸、形状、pin 位置、所在金属层, etc.)

- **DEF (Design Exchange Format)**: 描述整个芯片的 placement 和 routing.

- **Bookshelf**: 一套用于 VLSI 设计的开源文件格式, 包括:
    - **`.nodes`**: 描述 cell 的尺寸和类型.
    - **`.pl`**: 描述 cell 的 placement.
    - **`.nets`**: 描述 cell 之间的连接关系.
    - **`.scl`**: 描述 row.

- **CSR (Compressed Sparse Row)**: 用 index + data 进行**连续**存储的格式 (E.g., sparse matrix, [pin-list 表示法](../eda-3d-placement/eda-3d-placement.qmd), etc.)

:::{layout = "[50,50]"}
![Sparse matrix 原始形式](sparse-matrix.png){#fig-sparse-matrix width=75%}

![Sparse matrix 可以用三个数组来储存](sparse-matrix-csr.png){#fig-sparse-matrix-csr width=85%}
:::

### Packaging 封装

- **Wafer 晶圆, Die, Chiplet Arch**
    - Die 和 Tile: 一样的概念, 前者强调物理实体, 后者强调逻辑功能单元.

    ![Wafer 是圆圆的一整块, 上面可以切下来 $A,B,C,D$ 四种不同的 die; Chiplet 思想 (Use smaller dies) 与其如何提高良率、降低成本 @filho_2024_what](chiplet.png){#fig-chiplet}

:::{.column-margin}
![多个 Die 通过 D2D connection (die-to-die) 形成 SoC @filho_2024_what](die2soc.png){#fig-die2soc}
:::

- **3D IC** 常见类型:
    - **TSV-based**: 用 **TSV (Through-Silicon Via) 硅通孔**, 就是在硅片上打孔, 然后在孔内镀铜, 形成垂直的电连接通道. 但由于 large pitches and parasitics, 性能提升有限 @zhao2024analyticalheterogeneousdietodie3d. **BPV (Bond pad via)** 可能类似 TSV @10454441?
    - **Monolithic**: 一整块硅片上制造多个层次的电路, 成本高.
    - **F2F (Face-to-Face)**: 用 **HBT (Hybrid bonding terminal)** (或 **BPM (Bond pad metal)** @10454441) 端子连接上下层 Die (通过直接原子键合) @zhao2024analyticalheterogeneousdietodie3d.

- **pitch 间距**: 两个相邻的重复元件中心之间的距离. HBT 的优点就是 pitch 比较小 (fine), 集成度高.

:::{.column-margin}
![FinFET (鳍式场效应管) 的 transistor-to-transistor pitch 仅有 $57$ nm @brancheducation_2024_how.](finfet.png){#fig-finfet}
:::

- **RSMTs (Rectilinear Steiner Minimal Trees)**: 简单理解为 Manhattan 走线的最小生成树 (可以引入额外的 point 作为中间点, 称为 **Steiner points** @fig-steiner-pt, 原始给定的点一般是 pins). 

:::{layout = "[60, -4, 36]"}
![通过引入 Steiner point $S$ 可以减少线长](steiner-pt.png){width=90% #fig-steiner-pt}

![$\# \text{Steiner points} \le \# \text{pins} - 2$](num-steiner.png){width=85% #fig-num-steiner}
:::

### Placement 布局

- **HPWL (Half-Perimeter WireLength)**: 某种线长的计算方法.

- **Std cell, row, site, global placement, legalization, bin**: 见 [EDA Notes 笔记](../eda-notes/eda-notes.qmd#sec-eda-terms).

### Timing Analysis

- **RC 提取**: 从物理变量抽取电容、电阻.

- **STA (Static Timing Analysis)**: 静态时序分析 @liao_2023_dreamplace. 信号在导线上的传输是需要时间的. "Static" 指通过电路的电容、电阻算出电路的 delay (而不需要通过实际输入信号然后仿真).

- **Timing arc**: 若 pin $i$ 的信号变化会影响 pin $j$ 的信号变化, 则称 pin $i$ 到 pin $j$ 之间存在一个 timing arc (注意有方向).
    - **Cell arc**: 某个 cell (如 AND gate) 内部的 timing arc.
    - **Net/edge arc**: 金属层走线或 via 上的 timing arc.
    - **Arc delay**: 若 $(p_i, p_j)$ 间存在 timing arc, 则 arc delay 表示从 pin $p_i$ 信号变化到 pin $p_j$ 信号变化所需的时间.
    - **Driver**: 存在 output pin 是某信号的 source 的 cell @phdthesisAlgorithms2019.
    - **Sink**: 存在 input pin 接收某信号的 cell @phdthesisAlgorithms2019.


- **Slack (时序)裕量**: Timing arc 不可避免, 但 arc delay 必须满足要求即可, 信号不能提前到 (**Hold/early time violation**), 也不能晚到 (**Setup/late time violation**). 即信号到达时间 AT (arrival time) 有一个 required 范围 (见 @fig-slack): $$\operatorname{min} \text{RAT} \le \text{AT} \le \operatorname{max} \text{RAT}.$$

    ![Slack 的定义. $\text{slack} > 0$ 安全, $\text{slack} < 0$ 违规 @liao_2023_dreamplace.](slack.png){#fig-slack width=70%}

    - **WNS (Worst Negative Slack) $s_{\text{wns}}$**: 违规里面的最坏 slack @liao_2023_dreamplace (如果没有违规, 则 $s_{\text{wns}}$ 不存在).
    - **TNS (Total Negative Slack) $s_{\text{tns}}$**: 所有违规 slack 相加 @liao_2023_dreamplace (如果没有违规, 则 $s_{\text{tns}}$ 不存在).
        - 一般 WNS 和 TNS 都只关心 Primary output endpoint pins (**PO**, 如 flip-flop inputs, outputs ports @liao_2023_dreamplace) 中的违规情况.
    - **Critical path (CP)**: 造成 WNS 的那条路径[^cp].


[^cp]: 这个词在多个领域内都有使用 (比如项目管理中的 CPM), 总体来说想表达的就是「搅屎棍」的意思.

- **Buffer 缓冲器**: 输入等于输出的逻辑门, 但是输入的 `1` 相当于引出电源的 `1`, 可以增强驱动. 还可以调节时延

## ML Terms

- **ANN (Artificial Neural Network)**: 就是传统意义上的神经网络.

- **MSE (Mean Squared Error)**: 可用作 Loss function.

- **Hyperparameter 超参数**: 模型训练前需要设置的参数, 如学习率、batch size、层数, etc.

- **AI 幻觉**: AI 编造事实的现象.

- **FP32**: 32 位浮点数, 1 位符号位, 8 位指数位, 23 位尾数位, 精度高, 计算速度慢.
- **BF16**: Brain Floating Point 16, 1 位符号位, 8 位指数位, 7 位尾数位, 精度低, 计算速度快.

- **DAG (Directed Acyclic Graph) 计算图**: 有向无环图, 用来可视化一次计算过程 (哪些数据先算, 后面的数据依赖哪些数据), 由张量和算子组成.

- **NAS (Neural Architecture Search)**: 神经网络架构搜索, 自动化地搜索神经网络的最佳架构 (而不是人工设计) @mellor2021neuralarchitecturesearchtraining.

- **BIC (Brain-inspired Computing) / NM (Neuromorphic) Computing**: 比如 SNN (Spiking Neural Network, 与 ANN 是同层概念).
    - **ANN2SNN methods**: 将 ANN 转换为 SNN 的方法 @deng2025edgeintelligencespikingneural.
    - **EdgeSNN**: "Edge Intelligence based on SNNs" @deng2025edgeintelligencespikingneural. 

- **Federated Learning**: 为了避免公司不愿分享数据、用户隐私泄漏等问题, 将训练数据交付 cloud 不再可能, 所以我们先在边缘设备上训练模型, 然后用某种方法将各个边缘设备上学到的 "知识" 汇总到 cloud 上, 这就叫 **FL**. [@deng2025edgeintelligencespikingneural; @somvanshi2025tinymachinelearningtiny]

![ANN vs SNN @deng2025edgeintelligencespikingneural](ann-vs-snn.png){#fig-ann-vs-snn}


- **FM (Foundation Model)**: 基础模型. 一般为了解决一个问题往往会训练一个专门的模型 (task-specific model). 但 FM 是一种通用的模型, 在大规模、广泛、多样的数据 (多模态的, 文字/图像/音频) 上进行训练 (训练成本很高), 然后可以通过微调 (fine-tuning) 来适应各种下游任务 (如文本生成、图像识别、语音识别等).
    - **Edge-native foundation models**: 边缘化的 FM, 涉及到对大模型的 knowledge distillation, pruning, quantization 等技术, 以适应边缘设备的计算和存储限制 @somvanshi2025tinymachinelearningtiny.

- **VLA (Vision Language Action)**: 智能驾驶/机器人领域内的一种先进的多模态机器学习模型, 它结合了视觉、语言和动作三种能力, 旨在实现从感知输入直接映射到机器人控制动作的完整闭环能力.

- **Pretraining 预训练**: 用维基百科、书籍等未标注的大规模数据集对模型进行训练 (自监督的), 方法包括:
    - **Masked Language Modeling (MLM)**: 随机挖空, 然后预测挖空的词语.
    - **Next Sentence Prediction (NSP)**: 以句子为单位的 MLM.

- **Fine-tuning 微调**: 在预训练模型的基础上, 用少量标注数据对模型进行训练, 以适应特定任务 (比如电影评论->情感标签).
    - **Full fine-tuning 全参数微调**: 会更新模型的**所有**参数. 性能好, 但成本极高 (700 亿参数的 LLM 需要 1TB 显存).
    - **Parameter-efficient fine-tuning (PEFT) 参数高效微调**: 主流, 冻结 $99\%$ 以上的模型参数, 只更新少量参数 (E.g., LoRA).
    - **Instruction tuning/Supervised fine-tuning 指令微调/有监督微调 (SFT)**: 用指令-回答对微调, 如 "翻译成中文: How are you?" -> "你好吗?", 让模型会回答而只是文本补全.
    - **Alignment tuning/Reinforcement Learning with Human Feedback (RLHF) 对齐微调/基于人类反馈的强化学习**: SFT 微调后的模型不是最有帮助的/有害的/不符合价值观的, 让模型给出多个回答, 然后让**人类**打分, 用强化学习 (如 PPO) 进行强化学习微调.

### Computing in ML

- **FLOP (Floating-Point OPeration)**: 一次浮点运算包括一次加/减/乘/除.
    - **FLOPs (Floating-point Operations)** 
    - **FLOPS (Floating-point Operations Per Second)**: 

- **MAC (Multiply‑ACcumulate)**: $a \leftarrow a + (b \times c)$ 这种运算, 神经网络中有大量的 MAC 运算. 1 MAC = 2 FLOPs.
    - `torchprofile` 库可以统计模型中的 FLOPs 和 MACs.

- **Spase DNN**: 稀疏神经网络, 指网络中有大量的权重为零 (即不参与计算) 的神经网络.
    - 根据稀疏的结构不同, 可分为三类 (见 @fig-sparsity). 其中 Semi-structured Sparsity 的意思是比如权重矩阵每 $4$ 个权重就有 $2$ 个权重为零 (记做 $2:4$ sparsity) @sabih2025hardwaresoftwarecodesignriscvextensions.

        ![用权重矩阵展示 (a) Structured (b) unstructured (c) semi-structured sparsity @sabih2025hardwaresoftwarecodesignriscvextensions, 蓝色的格子代表权重为 $0$](sparsity.png){#fig-sparsity}

    - **Pruning**: 剪枝, 将神经网络中不重要的权重 (如接近零的权重) 设置为零.
        - **Unstructured Pruning**: 非结构化剪枝, 移除个别权重, 硬件控制复杂度大.
        - **Structured Pruning**: 结构化剪枝, 移除整个通道/滤波器/神经元等 @sabih2025hardwaresoftwarecodesignriscvextensions, 更适合硬件加速. (比如 @fig-sparsity (a) 就可通过 pruning 移除输入的绿色神经元和输出的红色神经元).
        - **Semi-structured Pruning**: 半结构化剪枝, 介于上述两者之间.

- **GEMM (GEneral Matrix-Matrix Multiplication)**: 通用矩阵乘法.

- **CIM (Compute In Memory)**: 存内计算.

- **tiling 分块/瓦片**: 在 CUDA 编程中, 由于 global memory 访问延迟高, 比如计算两个矩阵相加, 可以将上半和下半部分分别交给两个 block 里进行计算, 开辟两个 shared memory 来存储各自的半部分 (注意 shared memory 不在 block 间共享, 矩阵上下两半部分的相加刚好也是无依赖的! 如果是 GEMM 就不能这样分配!). shared memory 访问效率高.

### Optimizer in ML

- **Optimizer 优化器**: 更新模型参数的算法.

- **Gradient Descent (GD) 梯度下降[^gd]**: 所有优化方法都从这个基础方法改进而来.
    - **Batch Gradient Descent (BGD) 全批量梯度下降**: 用整个训练集计算梯度并更新参数.
    - **Stochastic Gradient Descent (SGD) 随机梯度下降**: 每次用一个样本计算梯度并更新参数.
    - **Mini-batch Gradient Descent 小批量梯度下降**: 每次用一个 mini-batch (如 32 个样本) 计算梯度并更新参数.

[^gd]: *Abuse of Terms* 现在说的 GD/SGD 就是指 Mini-batch 版本! 实际训练中不用 BGD (计算量太大) 和纯 SGD (不稳定)!

- **Momentum-based 动量优化器**: 引入历史项的加权平均 (等价于指数加权), 相当于给参数中的点赋予质量和惯性 (而不是没有质量), 不易受噪声影响, 可**加速**和**平滑**收敛、避免**陷入局部最优**[^momentum]. 也有一些基于次改良的版本:
    - **Nesterov Accelerated Gradient (NAG)**: 将未来的参数点的梯度也参与计算, 避免 overshoot. 开启这个功能无需设置额外的超参数, 以 `torch` 为例:

        ```python
        optimizer_nag = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)
        ```

[^momentum]: "SGD is a walking man downhill, slowly but steady. Momentum is a heavy ball running downhill, smooth and fast." @maciejbalawejder_2022_optimizers

- **Adaptive Gradient (Adagrad) 自适应梯度优化器**: 有利于 Sparse Features 的学习 (通过给每个参数分配不同的学习率! 或者理解为对参数进行归一化):

    ![Adagrad 给梯度平缓方向对应的参数 ($Y$) 更大的学习率 ($\alpha_Y = 0.05$) 来加快这个方向的下降 @tg_2020_why. 也可以用 "Normalize" 的角度理解.](adagrad.png){#fig-adagrad}



### ML Frameworks

- **Tensorflow, JAX, PyTorch**: 机器学习框架 @fig-mlsys. 其实就是一些 Python 库.

    ```python
    import tensorflow as tf
    import torch
    import jax.numpy as jnp
    ```

    - RISCV 上有 TfLM (TensorFlow Lite for Microcontrollers), 
    - **ONNX (Open Neural Network Exchange)**: 一种统一的描述神经网络结构的格式, 以上三种框架都支持导出为 ONNX 格式.

- **TVM, XLA (Accelerated Linear Algebra)**: 机器学习编译器 @fig-mlsys, 在以上三个框架内都有 python 的接口函数.

![AI 编译栈和编程体系](mlsys.png){#fig-mlsys width=80%}

### Benchmarks in ML

- **AUC (Area Under Curve)**: 二分类模型的性能评估指标, 越大越好.

- **F-score**: 二分类 (正类、负类) 模型的性能评估指标.
    - **TP (True Positive)**: 正类被正确分类为正类.
    - **FP (False Positive)**: 负类被错误分类为正类.
    - **FN (False Negative)**: 正类被错误分类为负类.
    - **Recall 召回率**: $TP/TP+FP$
    - **Precision 精确率**: $TP/TP+FN$
    - **F1-score**: Recall 和 Precision 的调和平均 (F-$\beta$ score 的特例)
    - **F-$\beta$ score**: 仅仅是给 recall 加了权重.

        ![](F-score.png)

- **A/B Test**: 类似双盲实验, 比如研究修改按钮颜色能否提升点击率? 新模型是否真的比旧模型好? 可以用这种方法进行对比实验.

### Related Philosophy

- **Symbol Grounded Problem**: 符号嵌入 (接地) 问题. 探讨的是符号 (或词语) 是如何在一个系统中获得意义的. 比如 "猫" 是一个符号, 但它不仅仅是一个符号, 它还与其它符号有所关联 (Grounded "嵌入"), 这种关联是 "猫" 的意义. 关于符号是如何嵌入的, 有以下几种观点:
    - **具身认知**: 意义必须通过一种感官、具身的方式与世界互动, 才能真正理解并嵌入符号. @The_Human_Developers_2025_cnblogs
    - **联结主义**: 符号的意义只取决于它与其它符号的关系 (有点范畴论的感觉哈哈). 符号可以通过网络中激活模式来进行嵌入. 这些模型并不明确地定义符号的意义, 而是通过训练大量数据, 学习感官输入与概念之间的关联. @The_Human_Developers_2025_cnblogs

## CPU Terms

- **PSR (Program Status Register)**: 程序状态寄存器. 有 NZVC (Negative, Zero, Overflow, Carry) 四个标志位. 

- **Hart (Hardware Thread)**: 硬件线程, 指一个独立的处理器核心, 包括一套流水线, 寄存器, PC 等等 (今后将不提处理器核心这个概念, 只提 Hart).
- **Benchmark**: 基准测试. 用于测试系统或工具的功能/性能.

- **QEMU (Quick Emulator)**: 开源的模拟器, 可模拟多种 CPU 架构 (如 ARM, x86, RISCV 等).

- **Renode**: 开源的模拟器, 主要面向嵌入式系统.

- **Endianness**[^endian]: 

    ![大端与小端 @Lazyparser_2025_bilibili](endianness.png){width=80%}

[^endian]: 记忆: 小端是自然的, 因为大部分人喜欢洗小头 (

- **MMU (Memory Management Unit)**: 内存管理单元, 负责虚拟内存和物理内存之间的映射.
    - **TLB (Translation Lookaside Buffer)**: 很像 CPU 的 Cache, 用于加速虚拟地址到物理地址的转换. 也有 TLB miss, TLB hit, spacial locality, temporal locality, etc. 这些概念.

- **PPA (Power, Performance, Area)**: 三个重要的设计指标.

- **DSA (Domain Specific Architecture)**

- **DDR (Double Data Rate)**: 一种 (双倍数据率) RAM, 在上升沿和下降沿各传输一次数据. **SDR** 是早期内存技术, 只在时钟上升沿传输数据.

## GPU Terms

- **GDDR (Graphics DDR)**: 显存 (每颗 GDDR6X 带宽 $80$ GB/s.)

- **HBM (High Bandwidth Memory)**: 高带宽内存 (每颗 HBM2E 带宽 $460$ GB/s.)

:::{.column-margin}
![AMD GPU 2015 采用 2.5D 封装](amd-gpu-2015.png){#fig-amd-gpu-2015}
:::

- **Kernel**: 在 GPU 上运行的函数. 

## RISCV

- **ABI (Abstract Binary Interface)**: 抽象二进制接口. 比如寄存器的使用约定 (比如函数传参用 `a0~a7`), 数据类型大小 (char 占几个字节等), 函数调用约定, 内存对齐等.

- **Hart (Hardware Thread)**: 硬件线程, 指一个独立的处理器核心, 包括一套流水线, 寄存器, PC 等等 (今后将不提处理器核心这个概念, 只提 Hart).

- **PMP (Physical Memory Protection)**: 物理内存保护. 

## C Compile Terms

- **gcc (GNU Compiler Collection)**: GNU 编译器集合, 包括 C、C++、Go 等编程语言的编译器.
    - gcc = clang (前端) + LLVM (后端) (在功能上)

- **IR (Intermediate Representation)**: 编译器在编译过程中形成的中间代码 (不一定只有一层, 可以有多层), 用于编译器优化和代码生成.
    - **GIMPLE**: gcc 生成的中间表示
    - **LLVM IR**: clang 生成的中间表示

- **MLIR**: 机器学习模型训练的中间表示.

- **GDB (GNU Debugger)**: GNU 调试器. 支持 Assembly, C/C++, Go, Rust 等.

- **elf (Executable Linkable Format)**: 可执行链接格式. 包含 `.o`, `a.out`, `.so` 等文件.
    - **Binutils (Binary Utilities)**: elf 文件处理相关工具, 包括:
        - `objdump`: 反汇编工具.
        - `objcopy`: 执行文件格式转换. elf 中还包含了很多运行时不需要的信息, `objcopy` 可将这些信息去掉生成 `bin` 文件.
        - `readelf`: 显示更多 elf 格式文件的信息.
        - `ar`: tar, 将多个文件打包成一个大文件.

:::{.column-margin}
![ELF 文件格式 @Lazyparser_2025_bilibili](elf-format.png)
:::

- **Cross Compilation**: 交叉编译, 即在另一台机器上面开发手里面的这台机器 (嵌入式开发, 或在 MacOS 编写 RISCV 的操作系统).
    - 构建 (build) 系统: 生成可执行程序的计算机.
    - 主机 (host) 系统: 运行可执行程序的计算机.
    - 目标 (target) 系统: 可执行程序运行的计算机架构

:::{.column-margin}
![交叉编译](cross-compilation.png)
:::

## Operating System Terms

- **RTOS (Real-Time Operating System)**: 实时操作系统, 用于嵌入式系统.
    - **FreeRTOS**: 设计小巧, 核心代码只有 3 到 4 个 C 文件, 支持 ARM, x86, RISCV @Lazyparser_2025_bilibili.
    - **RT-Thread**: 也是一个 RTOS

## YSYX Terms

- **AM (Abstraction Machine)**: 抽象机, 用程序模拟的硬件计算机.

- **NPC (New Processor Core)**: 指我们自己设计的处理器.


## Integrated Circuit Terms

- **VLSI (Very Large Scale Integration)**: 超大规模集成电路.
- **RGCN (Relational Graph Convolutional Network)**: 关系图卷积网络.

## Integrated Circuit Terms

- **VLSI (Very Large Scale Integration)**: 超大规模集成电路.

## Optimization

- **TSP (Travelling Salesman Problem)**: 旅行商问题. 给定若干城市与它们之间的距离, 目标是找出一条路径, 使旅行者每个城市恰好访问一次, 最终回到起点, 并且总旅行距离最短.

- **CVRP (Capacitated Vehicle Routing Problem)**: 带容量限制的车辆路径问题. 多辆车运送货物给多个城市, 每辆车只能装有限重量的货物, 目标是货物全送到并让运送距离最短.

- **FFSP (Flexible Flow Shop Problem)**: 灵活流水车间调度问题.

    ![FFSP](ffsp.png)



<!-- ## AnalogGYM Terms

- **FOM (Figure of Merit)**: 性能指标.

- **PVT (Process, Voltage, Temperature)**: 影响电路性能的三个主要因素.
    - **Process**: 工艺, e.g.,
        - TT (Typical-Typical): 典型工艺角, NMOS 和 PMOS 都是典型速度设计的目标工艺角
        - FF (Fast-Fast): 快-快工艺角, NMOS 和 PMOS 都比典型值快, 功耗通常较高，速度快
        - SS (Slow-Slow): 慢-慢工艺角, NMOS 和 PMOS 都比典型值慢, 功耗较低，但速度慢
        - FS (Fast-Slow): 快-慢工艺角, NMOS 快，PMOS 慢, 不对称的工艺条件
        - SF (Slow-Fast): 慢-快工艺角, NMOS 慢，PMOS 快, 另一种不对称条件NMOS慢，PMOS快
    - **PVT corner**: PVT 角, 某种特定的工艺、电压和温度组合 (一般是比较极端的组合, 所以称为 "corner").
    
- **GAT (Graph Attention Network)**: 图注意力网络.

- **MTRL (Multi-task Reinforcement Learning)**: 多任务强化学习.

- **PDK (Process Development Kit)**: 工艺开发套件.
    - **NDA (Non-Disclosure Agreement)**: 商业 PDK 必须对模型文件、器件参数、仿真结果保密 (这是将 ML 应用于电路设计的最大瓶颈之一 @li_2023_design).
    - **SKY130**: 开源 PDK, 由 Google 和 SkyWater Technology 在 2020 年共同开发的 130nm 开源工艺平台. -->


## References {.unnumbered}


- **ANN (Artificial Neural Network)**: 就是传统意义上的神经网络.

- **MSE (Mean Squared Error)**: 可用作 Loss function.

- **Hyperparameter 超参数**: 模型训练前需要设置的参数, 如学习率、batch size、层数, etc.

- **AI 幻觉**: AI 编造事实的现象.

- **FP32**: 32 位浮点数, 1 位符号位, 8 位指数位, 23 位尾数位, 精度高, 计算速度慢.
- **BF16**: Brain Floating Point 16, 1 位符号位, 8 位指数位, 7 位尾数位, 精度低, 计算速度快.

- **DAG (Directed Acyclic Graph) 计算图**: 有向无环图, 用来可视化一次计算过程 (哪些数据先算, 后面的数据依赖哪些数据), 由张量和算子组成.

- **NAS (Neural Architecture Search)**: 神经网络架构搜索, 自动化地搜索神经网络的最佳架构 (而不是人工设计) @mellor2021neuralarchitecturesearchtraining.

- **BIC (Brain-inspired Computing) / NM (Neuromorphic) Computing**: 比如 SNN (Spiking Neural Network, 与 ANN 是同层概念).
    - **ANN2SNN methods**: 将 ANN 转换为 SNN 的方法 @deng2025edgeintelligencespikingneural.
    - **EdgeSNN**: "Edge Intelligence based on SNNs" @deng2025edgeintelligencespikingneural. 

- **Federated Learning**: 为了避免公司不愿分享数据、用户隐私泄漏等问题, 将训练数据交付 cloud 不再可能, 所以我们先在边缘设备上训练模型, 然后用某种方法将各个边缘设备上学到的 "知识" 汇总到 cloud 上, 这就叫 **FL**. [@deng2025edgeintelligencespikingneural; @somvanshi2025tinymachinelearningtiny]

![ANN vs SNN @deng2025edgeintelligencespikingneural](ann-vs-snn.png){#fig-ann-vs-snn}


- **FM (Foundation Model)**: 基础模型. 一般为了解决一个问题往往会训练一个专门的模型 (task-specific model). 但 FM 是一种通用的模型, 在大规模、广泛、多样的数据 (多模态的, 文字/图像/音频) 上进行预训练 (训练成本极高 @tcheyan_2025_decentralized); 然后可以通过微调 (fine-tuning) 来适应各种下游任务 (如文本生成、图像识别、语音识别等). 比如 Meta 的 Llama 模型.
    - **Edge-native foundation models**: 边缘化的 FM, 涉及到对大模型的 knowledge distillation, pruning, quantization 等技术, 以适应边缘设备的计算和存储限制 @somvanshi2025tinymachinelearningtiny.

- **Pretraining 预训练**: 用维基百科、书籍等未标注的大规模数据集对模型进行训练 (自监督的), 方法包括:
    - **Masked Language Modeling (MLM)**: 随机挖空, 然后预测挖空的词语.
    - **Next Sentence Prediction (NSP)**: 以句子为单位的 MLM.

- **Post-training/Fine-tuning 后训练/微调**: 在预训练模型的基础上, 用少量标注数据对模型进行训练, 以适应特定任务 (比如电影评论->情感标签).
    - **Full fine-tuning 全参数微调**: 会更新模型的**所有**参数. 性能好, 但成本极高 (700 亿参数的 LLM 需要 1TB 显存).
    - **Parameter-efficient fine-tuning (PEFT) 参数高效微调**: 主流, 冻结 $99\%$ 以上的模型参数, 只更新少量参数 (E.g., LoRA).
    - **Instruction tuning/Supervised fine-tuning 指令微调/有监督微调 (SFT)**: 用**指令-回答对**微调 @tcheyan_2025_decentralized, 如 "翻译成中文: How are you?" -> "你好吗?", 让模型会回答而只是文本补全.
    - **Alignment tuning/Reinforcement Learning with Human Feedback (RLHF) 对齐微调/基于人类反馈的强化学习**: SFT 微调后的模型不是最有帮助的/有害的/不符合价值观的, RLHF 不是喂给模型更多数据, 而是让模型给出多个回答, 然后让**人类**打分 (Reward), 用强化学习 (如 PPO) 进行微调来最大化这个 Reward @tcheyan_2025_decentralized.

- **VLA (Vision Language Action)**: 智能驾驶/机器人领域内的一种先进的多模态机器学习模型, 它结合了视觉、语言和动作三种能力, 旨在实现从感知输入直接映射到机器人控制动作的完整闭环能力.

- **AIGC (AI-Generated Content)**: 生成式 AI.



### Computing in ML

- **Training/Inference 训练/推理**: Training 是用数据集来更新模型参数的过程 (一般用 Backpropagation); Inference 是用训练好的模型来进行 Forward propagation 的过程 @tcheyan_2025_decentralized.
    - Inference 比 Training 计算量小很多 (但是对大模型来说依然很大).
    - 训练成本: 主要来自 GPU, 比如 NVIDIA H100/B200 costs \$30K per unit @tcheyan_2025_decentralized, OpenAI 计划 2025 年底部署 100w 台 GPU! Altman 说 GPT-4 训练成本一亿美元.
    - **Decentralized/Distributed Training 分布式训练**: Blockchain 的成功说明不同地方的算力可以 contribute to the same thing. 分布式训练目标是设计一个 blockchain-like system, 鼓励所有能联网的闲置设备贡献算力来训练大模型, 实现 $0$ GPU 成本. [@tcheyan_2025_decentralized; @dong2025singleaiclustersurvey].
        - [**Prime Intellect's "Protocol"**](https://www.primeintellect.ai/blog/protocol) @_2025_introducing.

        ![分布式训练: The Third Epoch of AI @_2025_chakra.](third-epoch.png){#fig-third-epoch}

- **参数量**: 模型中所有可训练参数的数量, 比如 7B 指模型有 70 亿个可训练参数.

- **FLOP (Floating-Point OPeration)**: 一次浮点运算包括一次加/减/乘/除.
    - **FLOPs (Floating-point Operations)** 
    - **FLOPS (Floating-point Operations Per Second)**: 

- **MAC (Multiply‑ACcumulate)**: $a \leftarrow a + (b \times c)$ 这种运算, 神经网络中有大量的 MAC 运算. 1 MAC = 2 FLOPs.
    - `torchprofile` 库可以统计模型中的 FLOPs 和 MACs.

- **Spase DNN**: 稀疏神经网络, 指网络中有大量的权重为零 (即不参与计算) 的神经网络.
    - 根据稀疏的结构不同, 可分为三类 (见 @fig-sparsity). 其中 Semi-structured Sparsity 的意思是比如权重矩阵每 $4$ 个权重就有 $2$ 个权重为零 (记做 $2:4$ sparsity) @sabih2025hardwaresoftwarecodesignriscvextensions.

        ![用权重矩阵展示 (a) Structured (b) unstructured (c) semi-structured sparsity @sabih2025hardwaresoftwarecodesignriscvextensions, 蓝色的格子代表权重为 $0$](sparsity.png){#fig-sparsity}

    - **Pruning**: 剪枝, 将神经网络中不重要的权重 (如接近零的权重) 设置为零.
        - **Unstructured Pruning**: 非结构化剪枝, 移除个别权重, 硬件控制复杂度大.
        - **Structured Pruning**: 结构化剪枝, 移除整个通道/滤波器/神经元等 @sabih2025hardwaresoftwarecodesignriscvextensions, 更适合硬件加速. (比如 @fig-sparsity (a) 就可通过 pruning 移除输入的绿色神经元和输出的红色神经元).
        - **Semi-structured Pruning**: 半结构化剪枝, 介于上述两者之间.

- **GEMM (GEneral Matrix-Matrix Multiplication)**: 通用矩阵乘法.

- **CIM (Compute In Memory)**: 存内计算.

- **tiling 分块/瓦片**: 在 CUDA 编程中, 由于 global memory 访问延迟高, 比如计算两个矩阵相加, 可以将上半和下半部分分别交给两个 block 里进行计算, 开辟两个 shared memory 来存储各自的半部分 (注意 shared memory 不在 block 间共享, 矩阵上下两半部分的相加刚好也是无依赖的! 如果是 GEMM 就不能这样分配!). shared memory 访问效率高.

### Optimizer in ML

- **Optimizer 优化器**: 更新模型参数的算法.

- **Gradient Descent (GD) 梯度下降[^gd]**: 所有优化方法都从这个基础方法改进而来.
    - **Batch Gradient Descent (BGD) 全批量梯度下降**: 用整个训练集计算梯度并更新参数.
    - **Stochastic Gradient Descent (SGD) 随机梯度下降**: 每次用一个样本计算梯度并更新参数.
    - **Mini-batch Gradient Descent 小批量梯度下降**: 每次用一个 mini-batch (如 32 个样本) 计算梯度并更新参数.

[^gd]: *Abuse of Terms* 现在说的 GD/SGD 就是指 Mini-batch 版本! 实际训练中不用 BGD (计算量太大) 和纯 SGD (不稳定)!

- **Momentum-based 动量优化器**: 引入历史项的加权平均 (等价于指数加权), 相当于给参数中的点赋予质量和惯性 (而不是没有质量), 不易受噪声影响, 可**加速**和**平滑**收敛、避免**陷入局部最优**[^momentum]. 也有一些基于次改良的版本:
    - **Nesterov Accelerated Gradient (NAG)**: 将未来的参数点的梯度也参与计算, 避免 overshoot. 开启这个功能无需设置额外的超参数, 以 `torch` 为例:

        ```python
        optimizer_nag = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)
        ```

[^momentum]: "SGD is a walking man downhill, slowly but steady. Momentum is a heavy ball running downhill, smooth and fast." @maciejbalawejder_2022_optimizers

- **Adaptive Gradient (Adagrad) 自适应梯度优化器**: 有利于 Sparse Features 的学习 (通过给每个参数分配不同的学习率! 或者理解为对参数进行归一化):

    ![Adagrad 给梯度平缓方向对应的参数 ($Y$) 更大的学习率 ($\alpha_Y = 0.05$) 来加快这个方向的下降 @tg_2020_why. 也可以用 "Normalize" 的角度理解.](adagrad.png){#fig-adagrad}



### ML Frameworks

- **Tensorflow, JAX, PyTorch**: 机器学习框架 @fig-mlsys. 其实就是一些 Python 库.

    ```python
    import tensorflow as tf
    import torch
    import jax.numpy as jnp
    ```

    - RISCV 上有 TfLM (TensorFlow Lite for Microcontrollers), 
    - **ONNX (Open Neural Network Exchange)**: 一种统一的描述神经网络结构的格式, 以上三种框架都支持导出为 ONNX 格式.

- **TVM, XLA (Accelerated Linear Algebra)**: 机器学习编译器 @fig-mlsys, 在以上三个框架内都有 python 的接口函数.
    - **OpenXLA**: 中间表示 **StableHLO (Stable High-Level Optimizer)**, **XLA**, **PJRT** 的实现工程.

![AI 编译栈和编程体系](mlsys.png){#fig-mlsys width=80%}

### Benchmarks in ML

- **AUC (Area Under Curve)**: 二分类模型的性能评估指标, 越大越好.

- **F-score**: 二分类 (正类、负类) 模型的性能评估指标.
    - **TP (True Positive)**: 正类被正确分类为正类.
    - **FP (False Positive)**: 负类被错误分类为正类.
    - **FN (False Negative)**: 正类被错误分类为负类.
    - **Recall 召回率**: $TP/TP+FP$
    - **Precision 精确率**: $TP/TP+FN$
    - **F1-score**: Recall 和 Precision 的调和平均 (F-$\beta$ score 的特例)
    - **F-$\beta$ score**: 仅仅是给 recall 加了权重.

        ![](F-score.png)

- **A/B Test**: 类似双盲实验, 比如研究修改按钮颜色能否提升点击率? 新模型是否真的比旧模型好? 可以用这种方法进行对比实验.

### Related Philosophy

- **Symbol Grounded Problem**: 符号嵌入 (接地) 问题. 探讨的是符号 (或词语) 是如何在一个系统中获得意义的. 比如 "猫" 是一个符号, 但它不仅仅是一个符号, 它还与其它符号有所关联 (Grounded "嵌入"), 这种关联是 "猫" 的意义. 关于符号是如何嵌入的, 有以下几种观点:
    - **具身认知**: 意义必须通过一种感官、具身的方式与世界互动, 才能真正理解并嵌入符号. @The_Human_Developers_2025_cnblogs
    - **联结主义**: 符号的意义只取决于它与其它符号的关系 (有点范畴论的感觉哈哈). 符号可以通过网络中激活模式来进行嵌入. 这些模型并不明确地定义符号的意义, 而是通过训练大量数据, 学习感官输入与概念之间的关联. @The_Human_Developers_2025_cnblogs

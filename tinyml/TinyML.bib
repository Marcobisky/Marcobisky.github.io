@misc{a2021_deep,
  title = {Deep Learning Architecture},
  url = {https://gitee.com/hitsz-cslab/dla#https://gitee.com/hitsz-cslab/dla/tree/master/stupkt},
  urldate = {2025-07-15},
  year = {2021},
  organization = {Gitee.com}
}

@ARTICLE{2018arXiv180503648K,
  author = {{Kastner}, R. and {Matai}, J. and {Neuendorffer}, S.},
  title = "{Parallel Programming for FPGAs}",
  journal = {ArXiv e-prints},
  archivePrefix = "arXiv",
  eprint = {1805.03648},
  keywords = {Computer Science - Hardware Architecture},
  year = 2018,
  month = may
}

@misc{redmon2016lookonceunifiedrealtime,
      title={You Only Look Once: Unified, Real-Time Object Detection}, 
      author={Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
      year={2016},
      eprint={1506.02640},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1506.02640}, 
}


@article{Er_2025_bilibili,
	author	={上下求索电子Er},
	title	={[YOLO V1] 数据标注和输出张量_哔哩哔哩_bilibili},
	year	={2025},
	url	={https://www.bilibili.com/video/BV1gKwAeWEo4/?spm_id_from=333.788.player.switch&vd_source=42579e22289b6144ba0b2bdcf99834e3&p=3}
}

@article{Hack_2025_CSDN,
	author	={Hack 电子},
	title	={哈工大深度学习体系结构课程 | 实验2：YOLO算法量化加速-CSDN博客},
	year	={2025},
	url	={https://blog.csdn.net/HackEle/article/details/135944887}
}

@book{patt_2020_introduction,
  author = {Patt, Yale N and Patel, Sanjay J},
  publisher = {Mcgraw-Hill},
  title = {Introduction to Computing Systems : from Bits and Gates to c/c++ & beyond},
  year = {2020}
}

@article{Slchoi_2025_velog,
	author	={Slchoi},
	title	={Multi-Cycle Implementation & Pipelining},
	year	={2025},
	url	={https://velog.io/@taegon1998/4.2-4.3-Multi-Cycle-Implementation-Pipelining}
}

@book{murphy_2012_machine,
  author = {Murphy, Kevin P},
  publisher = {Mit Press},
  title = {Machine Learning : a Probabilistic Perspective},
  year = {2012}
}

// The fantastic animation
@article{The_Cpu_Is_2025_youtube,
	author	={QBayLogic},
	title	={CPU vs FPGA explained in a short animation - YouTube},
	year	={2025},
	url	={https://www.youtube.com/watch?v=BML1YHZpx2o}
}

@article{Simulation_Time._Putting_2025_oscc,
	author	={YSYX},
	title	={E5 从 RTL 代码到可流片版图 | 官方文档},
	year	={2025},
	url	={https://ysyx.oscc.cc/docs/2407/e/5.html#%E6%89%93%E5%8D%B0%E5%B9%B6%E6%9F%A5%E7%9C%8B%E6%B3%A2%E5%BD%A2}
}

@article{Lazyparser_2025_bilibili,
	author	={Lazyparser},
	title	={Compilation and Linker},
	year	={2025},
	url	={https://www.bilibili.com/video/BV1Q5411w7z5?spm_id_from=333.788.videopod.episodes&vd_source=42579e22289b6144ba0b2bdcf99834e3&p=5}
}

@article{Voice_2025_youtube,
	author	={MIT HAN Lab},
	title	={Lecture 2 - Basics of Neural Networks (MIT 6.5940, Fall 2023)},
	year	={2025},
	url	={https://www.youtube.com/watch?v=ieg0RJb7TeI&list=PL80kAHvQbh-pT4lCkDT53zT8DKmhE0idB&index=4}
}

@article{emory,
	author	={Shun Yan Cheung},
	title	={Lecture notes on Computer Science courses: Computer Architecture (CS355)},
	year	={2025},
	url	={https://www.cs.emory.edu/~cheung/Courses/355/Syllabus/syl.html#CURRENT}
}

@article{li_2023_design,
  author = {Li, Zonghao and Carusone, Anthony Chan},
  month = {10},
  pages = {01-09},
  title = {Design and Optimization of Low-Dropout Voltage Regulator Using Relational Graph Neural Network and Reinforcement Learning in Open-Source SKY130 Process},
  doi = {10.1109/iccad57390.2023.10323720},
  year = {2023},
  journal = {2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)}
}

@article{Intel_2025_intel,
	author	={Intel},
	title	={What Is Edge Computing? – Intel},
	year	={2025},
	url	={https://www.intel.com/content/www/us/en/learn/what-is-edge-computing.html?utm_source=chatgpt.com}
}

@article{Asking_Questions_2025_youtube,
	author	={Asking Questions},
	title	={Introduction to FPGAs and ML inference with hls4ml (Benjamin Ramhorst, 8 November 2024) - YouTube},
	year	={2025},
	url	={https://www.youtube.com/watch?v=2y3GNY4tf7A}
}

@article{Duarte:2018ite,
    author = "Duarte, Javier and others",
    title = "{Fast inference of deep neural networks in FPGAs for particle physics}",
    eprint = "1804.06913",
    archivePrefix = "arXiv",
    primaryClass = "physics.ins-det",
    reportNumber = "FERMILAB-PUB-18-089-E",
    doi = "10.1088/1748-0221/13/07/P07027",
    journal = "JINST",
    volume = "13",
    number = "07",
    pages = "P07027",
    year = "2018"
}

@article{Fusion_Energy_Sciences_2025_energy,
	author	={Fusion Energy Sciences},
	title	={AI Tackles Disruptive Tearing Instability in Fusion Plasma | Department of},
	year	={2025},
	url	={https://www.energy.gov/science/fes/articles/ai-tackles-disruptive-tearing-instability-fusion-plasma?utm_source=chatgpt.com}
}

@misc{sali2025realtimefpgabased,
      title={Real Time FPGA Based CNNs for Detection, Classification, and Tracking in Autonomous Systems: State of the Art Designs and Optimizations}, 
      author={Safa Mohammed Sali and Mahmoud Meribout and Ashiyana Abdul Majeed},
      year={2025},
      eprint={2509.04153},
      archivePrefix={arXiv},
      primaryClass={cs.AR},
      url={https://arxiv.org/abs/2509.04153}, 
}


@misc{sabih2025hardwaresoftwarecodesignriscvextensions,
    title={Hardware/Software Co-Design of RISC-V Extensions for Accelerating Sparse DNNs on FPGAs}, 
    author={Muhammad Sabih and Abrarul Karim and Jakob Wittmann and Frank Hannig and Jürgen Teich},
    year={2025},
    eprint={2504.19659},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2504.19659}, 
}

@misc{mellor2021neuralarchitecturesearchtraining,
	title={Neural Architecture Search without Training}, 
	author={Joseph Mellor and Jack Turner and Amos Storkey and Elliot J. Crowley},
	year={2021},
	eprint={2006.04647},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2006.04647}, 
}

@misc{somvanshi2025tinymachinelearningtiny,
	title={From Tiny Machine Learning to Tiny Deep Learning: A Survey}, 
	author={Shriyank Somvanshi and Md Monzurul Islam and Gaurab Chhetri and Rohit Chakraborty and Mahmuda Sultana Mimi and Sawgat Ahmed Shuvo and Kazi Sifatul Islam and Syed Aaqib Javed and Sharif Ahmed Rafat and Anandi Dutta and Subasish Das},
	year={2025},
	eprint={2506.18927},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2506.18927}, 
}

@misc{jung2024optimizingdeploymenttinytransformers,
	title={Optimizing the Deployment of Tiny Transformers on Low-Power MCUs}, 
	author={Victor J. B. Jung and Alessio Burrello and Moritz Scherer and Francesco Conti and Luca Benini},
	year={2024},
	eprint={2404.02945},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2404.02945}, 
}

@article{Muir2025,
	author    = {Dylan Richard Muir and Sadique Sheik},
	title     = {The road to commercial success for neuromorphic technologies},
	journal   = {Nature Communications},
	year      = {2025},
	volume    = {16},
	number    = {1},
	pages     = {3586},
	doi       = {10.1038/s41467-025-57352-1},
	url       = {https://doi.org/10.1038/s41467-025-57352-1},
	abstract  = {Neuromorphic technologies adapt biological neural principles to synthesise high-efficiency computational devices, characterised by continuous real-time operation and sparse event-based communication. After several false starts, a confluence of advances now promises widespread commercial adoption. Gradient-based training of deep spiking neural networks is now an off-the-shelf technique for building general-purpose Neuromorphic applications, with open-source tools underwritten by theoretical results. Analog and mixed-signal Neuromorphic circuit designs are being replaced by digital equivalents in newer devices, simplifying application deployment while maintaining computational benefits. Designs for in-memory computing are also approaching commercial maturity. Solving two key problems—how to program general Neuromorphic applications; and how to deploy them at scale—clears the way to commercial success of Neuromorphic processors. Ultra-low-power Neuromorphic technology will find a home in battery-powered systems, local compute for internet-of-things devices, and consumer wearables. Inspiration from uptake of tensor processors and GPUs can help the field overcome remaining hurdles.},
	issn      = {2041-1723}
}

@misc{deng2025edgeintelligencespikingneural,
	title={Edge Intelligence with Spiking Neural Networks}, 
	author={Shuiguang Deng and Di Yu and Changze Lv and Xin Du and Linshan Jiang and Xiaofan Zhao and Wentao Tong and Xiaoqing Zheng and Weijia Fang and Peng Zhao and Gang Pan and Schahram Dustdar and Albert Y. Zomaya},
	year={2025},
	eprint={2507.14069},
	archivePrefix={arXiv},
	primaryClass={cs.DC},
	url={https://arxiv.org/abs/2507.14069}, 
}

@article{Jin2025,
	author    = {Miao Jin and Xiaohong Wang and Ce Guo and Shufan Yang},
	title     = {Research on target detection for autonomous driving based on ECS-spiking neural networks},
	journal   = {Scientific Reports},
	year      = {2025},
	volume    = {15},
	number    = {1},
	pages     = {13725},
	doi       = {10.1038/s41598-025-97913-4},
	url       = {https://doi.org/10.1038/s41598-025-97913-4},
	abstract  = {In response to the increasing demands for improved model performance and reduced energy consumption in object detection tasks relevant to autonomous driving, this research presents an advanced YOLO model, designated as ECSLIF-YOLO, which is based on the Leaky Integrate-and-Fire with Extracellular Space (ECS-LIF) framework. The primary aim of this model is to tackle the issues associated with the high energy consumption of traditional artificial neural networks (ANNs) and the suboptimal performance of existing spiking neural networks (SNNs). Empirical findings demonstrate that ECSLIF-YOLO achieves a peak mean Average Precision (mAP) of 0.917 on the BDD100K and KITTI datasets, thereby aligning with the accuracy levels of conventional ANNs while exceeding the performance of current direct-training SNN approaches without incurring additional energy costs. These findings suggest that ECSLIF-YOLO is particularly well-suited to assist the development of efficient and reliable systems for autonomous driving.},
	issn      = {2045-2322}
}
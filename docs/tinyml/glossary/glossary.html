<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Glossary 名词解释 – TinyML</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../research-proposal/research-proposal.html" rel="next">
<link href="../resources/resources.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-6353c5142b84b22f6683470407aecb9b.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-5549b3ede58740172b4e45471f64731a.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-6353c5142b84b22f6683470407aecb9b.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../index.html">Prologue</a></li><li class="breadcrumb-item"><a href="../glossary/glossary.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Glossary 名词解释</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">TinyML</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Prologue</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction 引入</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../resources/resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Resources 学习资料汇总</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../glossary/glossary.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Glossary 名词解释</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../research-proposal/research-proposal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Research Proposal: New Inference Paradigms for ML at the Edge</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Environment Setup</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../env-setup/env-setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">FPGA 开发环境配置</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">EDA</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../eda-notes/eda-notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">EDA Notes 笔记</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Crash Courses</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../c-riscv-asm/c-riscv-asm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">C 和 RISCV 汇编</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../riscv/riscv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">RISCV ISA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cc-os/cc-os.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">OS 操作系统原理</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cc-coding/cc-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Random Notes on Coding</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cc-cli/cc-cli.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Basic Linux CLI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cc-fpga/cc-fpga.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">FPGA 原理速成</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cc-cpu/cc-cpu.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">CPU 原理速成</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cc-gpu/cc-gpu.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">GPU 原理速成</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Neural Network</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nn-essence/nn-essence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">The Essence of NN 神经网络的本质</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nn-arch/nn-arch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">NN Architectures 常见网络架构</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">ML Accelerators</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hls-design/HLS-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">HLS Design FPGA 并行编程</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">CFU Playground</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cfu-proj-struct/cfu-proj-struct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">CFU-Playground 工程结构</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#general-terms" id="toc-general-terms" class="nav-link active" data-scroll-target="#general-terms">General Terms</a></li>
  <li><a href="#fpga-terms" id="toc-fpga-terms" class="nav-link" data-scroll-target="#fpga-terms">FPGA Terms</a>
  <ul class="collapse">
  <li><a href="#general" id="toc-general" class="nav-link" data-scroll-target="#general">General</a></li>
  <li><a href="#interface" id="toc-interface" class="nav-link" data-scroll-target="#interface">Interface</a></li>
  <li><a href="#zynq" id="toc-zynq" class="nav-link" data-scroll-target="#zynq">ZYNQ</a></li>
  <li><a href="#file-formats" id="toc-file-formats" class="nav-link" data-scroll-target="#file-formats">File formats</a></li>
  <li><a href="#hdl" id="toc-hdl" class="nav-link" data-scroll-target="#hdl">HDL</a></li>
  <li><a href="#fpga-principles" id="toc-fpga-principles" class="nav-link" data-scroll-target="#fpga-principles">FPGA Principles</a></li>
  <li><a href="#fpga-structure-结构" id="toc-fpga-structure-结构" class="nav-link" data-scroll-target="#fpga-structure-结构">FPGA Structure 结构</a></li>
  <li><a href="#verification-验证" id="toc-verification-验证" class="nav-link" data-scroll-target="#verification-验证">Verification 验证</a></li>
  </ul></li>
  <li><a href="#open-source-tools" id="toc-open-source-tools" class="nav-link" data-scroll-target="#open-source-tools">Open Source Tools</a></li>
  <li><a href="#sec-eda-terms" id="toc-sec-eda-terms" class="nav-link" data-scroll-target="#sec-eda-terms">EDA Terms</a>
  <ul class="collapse">
  <li><a href="#packaging-封装" id="toc-packaging-封装" class="nav-link" data-scroll-target="#packaging-封装">Packaging 封装</a></li>
  <li><a href="#placement-布局" id="toc-placement-布局" class="nav-link" data-scroll-target="#placement-布局">Placement 布局</a></li>
  <li><a href="#timing-analysis" id="toc-timing-analysis" class="nav-link" data-scroll-target="#timing-analysis">Timing Analysis</a></li>
  </ul></li>
  <li><a href="#ml-terms" id="toc-ml-terms" class="nav-link" data-scroll-target="#ml-terms">ML Terms</a>
  <ul class="collapse">
  <li><a href="#general-terms-1" id="toc-general-terms-1" class="nav-link" data-scroll-target="#general-terms-1">General Terms</a></li>
  <li><a href="#sec-cv-terms" id="toc-sec-cv-terms" class="nav-link" data-scroll-target="#sec-cv-terms">CV 计算机视觉相关</a></li>
  <li><a href="#transformer-相关" id="toc-transformer-相关" class="nav-link" data-scroll-target="#transformer-相关">Transformer 相关</a></li>
  <li><a href="#agent-相关" id="toc-agent-相关" class="nav-link" data-scroll-target="#agent-相关">Agent 相关</a></li>
  <li><a href="#computing-in-ml" id="toc-computing-in-ml" class="nav-link" data-scroll-target="#computing-in-ml">Computing in ML</a></li>
  <li><a href="#optimizer-in-ml" id="toc-optimizer-in-ml" class="nav-link" data-scroll-target="#optimizer-in-ml">Optimizer in ML</a></li>
  <li><a href="#ml-frameworks" id="toc-ml-frameworks" class="nav-link" data-scroll-target="#ml-frameworks">ML Frameworks</a></li>
  <li><a href="#benchmarks-in-ml" id="toc-benchmarks-in-ml" class="nav-link" data-scroll-target="#benchmarks-in-ml">Benchmarks in ML</a></li>
  <li><a href="#related-philosophy" id="toc-related-philosophy" class="nav-link" data-scroll-target="#related-philosophy">Related Philosophy</a></li>
  </ul></li>
  <li><a href="#pu-terms" id="toc-pu-terms" class="nav-link" data-scroll-target="#pu-terms">PU Terms</a>
  <ul class="collapse">
  <li><a href="#cpu-terms" id="toc-cpu-terms" class="nav-link" data-scroll-target="#cpu-terms">CPU Terms</a></li>
  <li><a href="#gpu-terms" id="toc-gpu-terms" class="nav-link" data-scroll-target="#gpu-terms">GPU Terms</a></li>
  <li><a href="#memory-存储器-terms" id="toc-memory-存储器-terms" class="nav-link" data-scroll-target="#memory-存储器-terms">Memory 存储器 Terms</a></li>
  </ul></li>
  <li><a href="#riscv" id="toc-riscv" class="nav-link" data-scroll-target="#riscv">RISCV</a></li>
  <li><a href="#c-compile-terms" id="toc-c-compile-terms" class="nav-link" data-scroll-target="#c-compile-terms">C Compile Terms</a></li>
  <li><a href="#operating-system-terms" id="toc-operating-system-terms" class="nav-link" data-scroll-target="#operating-system-terms">Operating System Terms</a></li>
  <li><a href="#ysyx-terms" id="toc-ysyx-terms" class="nav-link" data-scroll-target="#ysyx-terms">YSYX Terms</a></li>
  <li><a href="#integrated-circuit-terms" id="toc-integrated-circuit-terms" class="nav-link" data-scroll-target="#integrated-circuit-terms">Integrated Circuit Terms</a></li>
  <li><a href="#optimization" id="toc-optimization" class="nav-link" data-scroll-target="#optimization">Optimization</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../index.html">Prologue</a></li><li class="breadcrumb-item"><a href="../glossary/glossary.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Glossary 名词解释</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Glossary 名词解释</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>Glossary is important and irrelevant at the same time.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>NOTE</strong>: 笔者之所以不把所有 Terms 放在相应的章节里面讲而是列举在这里的动机主要是 很多概念比较基础, 并且对 big picture 影响不大. 需要展开解释的概念我会放 hyperlink.</p>
</blockquote>
<section id="general-terms" class="level2">
<h2 class="anchored" data-anchor-id="general-terms">General Terms</h2>
<ul>
<li><p><strong>CFU</strong>: Custom Function Unit (自定义功能单元). 为 ML 某些耗时的计算 (如卷积、矩阵乘法、位操作等) 定制的指令加速硬件模块.</p>
<ul>
<li>一旦主处理器执行到特定的 CFU 指令，就会将数据发送给 CFU 处理，然后 CFU 返回结果.</li>
<li><strong>FPU</strong>: Floating Point Unit (浮点运算单元), 是 CPU 中专门处理浮点数运算的硬件组件.</li>
</ul></li>
<li><p><strong>Git LFS</strong>: Git Large File Storage. 解决了 github 不能上传大文件的问题. 使用:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt-get install git-lfs</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> lfs install <span class="co"># 在项目目录中初始化 Git LFS</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> lfs pull <span class="co"># 下载实际文件</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>然后原来的文件的格式就会从文本格式变为真正的 ZIP 文件, 可以通过下面的命令查看:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">file</span> test.zip <span class="co"># 返回 </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
</section>
<section id="fpga-terms" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="fpga-terms">FPGA Terms</h2>
<section id="general" class="level3">
<h3 class="anchored" data-anchor-id="general">General</h3>
<ul>
<li><p><strong>TfLM</strong>: TensorFlow Lite for Microcontrollers.</p>
<ul>
<li><strong>PDTI8</strong>: Person DeTection Int 8</li>
</ul></li>
<li><p><strong>Gateware</strong>: 用软件编写的硬件电路. (既不是 Software, 也不是 Hardware).</p></li>
<li><p><strong>HPS</strong>: High Performance System.</p>
<ul>
<li><code>PLATFORMS=common_soc sim hps</code>, 三个平台. <code>common_soc</code> 指标准的 FPGA 开发平台; <code>sim</code> 指用 Verilator 进行软件仿真.</li>
</ul></li>
<li><p><strong>SoC (System on Chip) FPGA 片上系统</strong>: 比如 ZYNQ 有 PL 和 PS, <strong>一块硅芯片</strong> 就可以实现整个系统的功能 (而不是要组合多个芯片 (Chiplet)). 有时 Chiplets 组成的系统也叫 SoC, 但严格来说 SoC 是指单芯片系统.</p></li>
<li><p><strong>ACAP (Adaptive Compute Acceleration Platform)</strong>: 集成了专用 AI 引擎／DSP阵列、Network-on-chip (NoC)、高带宽存储接口 (如 HBM) 等异构硬件资源 <span class="citation" data-cites="sali2025realtimefpgabased"><a href="#ref-sali2025realtimefpgabased" role="doc-biblioref">[1]</a></span>, 如 Xilinx Versal 系列.</p></li>
<li><p><strong>IP Core</strong>: Intellectual Property Core. 由一方 (开发者或公司) 设计，并通过许可授权给其他设计者使用。常见的 IP 核包括 CPU 内核、以太网控制器、内存控制器等.</p>
<ul>
<li><strong>Soft IP</strong>: 软核</li>
<li><strong>Hard IP</strong>: 硬核</li>
</ul></li>
<li><p><strong><code>.vcd</code>, <code>fst</code></strong>: 波形文件格式, 后者占空间更小, 但只受 GTKWave 支持 <span class="citation" data-cites="Simulation_Time._Putting_2025_oscc"><a href="#ref-Simulation_Time._Putting_2025_oscc" role="doc-biblioref">[2]</a></span>.</p></li>
</ul>
</section>
<section id="interface" class="level3">
<h3 class="anchored" data-anchor-id="interface">Interface</h3>
<ul>
<li><p><strong>PMOD (Peripheral Module) 接口</strong>: 一组 2*6 排针的引脚 PMOD. 定义了电源、地线、以及最多 8 条可用于通信的信号线. PMOD模块通常通过 SPI、I2C 或 GPIO (通用数字输入输出) 与主控通信. 你可以买到很多支持 PMOD 的模块, 如传感器、显示屏、存储器等.</p></li>
<li><p><strong>JTAG 接口</strong>: 一种用于调试和编程的标准接口.</p></li>
<li><p><strong>AXI (Advanced eXtensible Interface) 接口</strong>: CPU 与外设 (内存控制器, DMA, CFU, IP 核) 之间的通信协议.</p>
<ul>
<li>比如 ZYNQ 的 <strong>PS (Processing System)</strong> 和 <strong>PL (Programmable Logic)</strong> 之间的通信就是通过 AXI 接口 (见 <a href="../cc-fpga/cc-fpga.html#sec-ps-structure">FPGA 原理速成</a>).</li>
</ul></li>
</ul>
</section>
<section id="zynq" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="zynq">ZYNQ</h3>
<ul>
<li><strong>核心商业模式</strong>:
<ul>
<li><strong>IP 提供商</strong>: 设计 IP 核并授权给芯片设计制造商使用. E.g., ARM (CPU 内核设计)</li>
<li><strong>芯片设计制造商</strong>: 购买 IP 核并设计和生产关键芯片. E.g., Xilinx (被 AMD 收购), ST (STM32 核心芯片的制造商).</li>
<li><strong>开发板制造商</strong>: 从芯片设计制造商处采购芯片, 并设计供电电路、时钟电路、将方形黑色的芯片底部的引脚引出接入各种物理接口、设计 PCB 等, 最终生产出开发板. E.g., Alinx, 正点原子, Digilent.</li>
</ul></li>
<li><strong>命名规则</strong>
<ul>
<li>E.g., ZYNQ XC7Z010 CLG400ABX2021 D6168711A, XC7: 7 系列 (Xilinx Corporation), Z: ZYNQ, 010: 逻辑资源规模 (越小越少), CLG: 封装类型 (Chip-Scale Lead-Free BGA (Ball Grid Array)), 400: 引脚数, ABX: 温度、性能等级, 2021: 生产年份, D6168711A: 可理解为序列号.</li>
<li>ZYNQ 7010 SoCs 包括 XC7Z010 等很多型号.</li>
</ul></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="zynq-7010-board.png" class="img-fluid figure-img"></p>
<figcaption>ZYNQ 7010 实物图: Xilinx 与 Alinx 公司分别负责的部分.</figcaption>
</figure>
</div>
</div></div><ul>
<li><p><strong>APU (Application Processing Unit)</strong>: ZYNQ PS 内部的一个双核 ARM Cortex-A9 CPU. (就是 CPU, 见 <a href="../cc-fpga/cc-fpga.html#sec-ps-structure">FPGA 原理速成</a>)</p></li>
<li><p><strong>MIO (Multiplexed I/O)</strong>: ZYNQ PS 黑色芯片里面有多种外设: SPI, IIC, CAN, UART, etc. 比如 UART 主要涉及 TX 和 RX 两类信号, 这两类信号需要通过 MIO 与用户交互. 但是 BGA 封装出来的引脚很少 (XC7 只有 54 根), 需要进行复用.</p>
<ul>
<li><strong>EMIO (Extended MIO)</strong>: 先要通过 PL 再与用户交互.</li>
</ul></li>
<li><p><strong>GIC (Generic Interrupt Controller)</strong>: 通用中断控制器, 收集外设、PL 发来的中断请求, 按优先级分配给 APU 中的两个核. 相当于 STM32 里面的 NVIC (Nested Vectored Interrupt Controller), 只不过 NVIC 只需要给到一个核.</p></li>
</ul>
</section>
<section id="file-formats" class="level3">
<h3 class="anchored" data-anchor-id="file-formats">File formats</h3>
<ul>
<li><p><strong><code>.pcf</code> 文件</strong>: Physical Constraints File. <code>.pcf</code> 文件告诉工具：Verilog 中的某个逻辑信号，物理上应该接到 FPGA 的哪个 pin. 比如:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode txt code-with-copy"><code class="sourceCode default"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>set_io D1 B5</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>表示把 <code>D1</code> (在 <code>.v</code> 文件中定义的) 信号连接到 FPGA 的 B5 引脚.</p>
<ul>
<li><strong><code>.xdc</code> 文件</strong>: Xilinx Design Constraints File (Vivado 工具使用的约束文件, a.k.a., Master Constraints File 主约束文件). <a href="https://raw.githubusercontent.com/Digilent/digilent-xdc/master/Arty-A7-35-Master.xdc">Arty 35T xdc 文件</a></li>
</ul></li>
<li><p><strong><code>.vmem</code> 文件</strong>: Verilog Memory File. 存放测试时 FPGA RAM/ROM 中的初始数据, 然后 testbench 文件会读取这个文件并将数据加载到 FPGA 内存中. 格式如下:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode verilog code-with-copy"><code class="sourceCode verilog"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="op">@</span><span class="dv">00000000</span>  <span class="co">// 32位地址：0x00000000</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="dv">00010203</span>   <span class="co">// 地址0x00000000 的内容：0x00010203</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="dv">04050607</span>   <span class="co">// 地址0x00000004 的内容：0x04050607</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="dv">08090</span>A0B   <span class="co">// 地址0x00000008 的内容：0x08090A0B</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="op">@</span><span class="dv">00000010</span>  <span class="co">// 跳转到地址0x00000010</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>FFFFFFFF   <span class="co">// 地址0x00000010 的内容：0xFFFFFFFF</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
</section>
<section id="hdl" class="level3">
<h3 class="anchored" data-anchor-id="hdl">HDL</h3>
<ul>
<li><p><strong>HLS</strong>: High-Level Synthesis. 用 C/C++ 等高级语言来写硬件电路设计.</p>
<ul>
<li><strong>Scala (Scalable language)</strong>: 一种专门生成其它 DSL (Domain Specific Language) 的语言. 生成的语言包括:
<ul>
<li><strong>SpinalHDL</strong>: 一种 Hardware Description Language (HDL). 可用来生成更底层的 Verilog 代码.
<ul>
<li><strong><a href="https://github.com/SpinalHDL/VexRiscv">VexRiscv Soft CPU</a></strong>: 用 SpinalHDL 写的一个 高度可配置的 RISC-V soft CPU 内核 (soft 的意思就是 CPU 不是硬件焊死的 (“hard CPU”) , 而是部署在 FPGA 上可以改变结构的).</li>
</ul></li>
<li><strong>Chisel</strong>: 另一种 HDL.</li>
<li><strong>Scalac</strong>: Scala 编译器.</li>
<li><strong>sbt</strong>: Scala Build导出 Tool. 配置依赖、插件和调用 scalac. 会在指定目录下面生成 <code>.v</code> 或 <code>.sv</code> 文件.
<ul>
<li><strong>FIRRTL (Flexible Intermediate Representation for RTL, <code>.fir</code>)</strong>: 一种用于硬件设计的中间表示 (加上 <code>--dump-fir</code> 选项即可, <code>dump</code> 一般表示「导出」). 可由 Chisel 生成, 然后再转换为 Verilog.
<ul>
<li><strong>ChiselStage</strong>: Chisel 的一个组件, 将 Chisel 转换为 FIRRTL.</li>
<li><strong>Firtool</strong>: 将 FIRRTL 转换为 Verilog.</li>
</ul></li>
</ul></li>
<li><strong>Mill</strong>: 跟 sbt 类似, 但更轻量.</li>
</ul></li>
<li><strong>Amaranth</strong>: 一个 Python 库, 也是用于硬件描述和设计. 可生成 Verilog 代码.</li>
</ul></li>
<li><p><strong>RTL (Register Transfer Level)</strong>: 通俗说就是 verilog 代码. 可视为芯片设计的前端.</p>
<div id="fig-design-level" class="quarto-float quarto-figure quarto-figure-center anchored" width="80%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-design-level-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="design-level.png" id="fig-design-level" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-design-level-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1
</figcaption>
</figure>
</div></li>
</ul>
</section>
<section id="fpga-principles" class="level3">
<h3 class="anchored" data-anchor-id="fpga-principles">FPGA Principles</h3>
<ul>
<li><strong>PAR</strong>： Place and Route. 布局布线.</li>
</ul>
</section>
<section id="fpga-structure-结构" class="level3">
<h3 class="anchored" data-anchor-id="fpga-structure-结构">FPGA Structure 结构</h3>
<ul>
<li><p><strong>BLE, CLB (Slice, LAB, ALM), SB</strong>: 见 <a href="../cc-fpga/cc-fpga.html#sec-pl-structure">FPGA 原理速成</a>.</p></li>
<li><p><strong>LUT (Look-Up Table)</strong>: 查找表. 所有写 <code>Verilog</code> 的行为一般都会被综合成 LUT + FF 的结构.</p></li>
<li><p><strong>DSP (Digital Signal Processing) Block</strong>: FPGA 上专门进行数值运算 (乘加) 的硬件模块 (是卷积、矩阵乘法核心).</p>
<ul>
<li><strong>LUT-based DSP</strong>: 与 DSP Block 有本质的区别, 综合器会把它看成 LUT + FF 结构, 而不是调用板子上的 DSP Block 硬件资源.</li>
</ul></li>
</ul>
</section>
<section id="verification-验证" class="level3">
<h3 class="anchored" data-anchor-id="verification-验证">Verification 验证</h3>
<blockquote class="blockquote">
<p>验证是芯片设计很重要的一环, 下面将简要介绍 Verification 的一些概念, 遵循认识论原则.</p>
</blockquote>
<ul>
<li><p><strong>DUT</strong>: Device Under Test. 被测试的模块.</p></li>
<li><p><strong>TB (Testbench)</strong>: 狭义来说就是用 <code>verilog</code> 写的测试代码 (<code>initial begin</code> 之类的). 但写过都知道有以下缺点:</p>
<ul>
<li>基本上只能验证模块的功能正确性.</li>
<li>输入什么信号都要自己写, 很费时, 而且缺乏随机性.</li>
</ul></li>
<li><p><strong>UVM (Universal Verification Methodology)</strong>: 验证方法学.</p></li>
<li><p><strong>Smoke Test 冒烟测试</strong>: 最基础耗时最短的测试, 软件的话就是能跑就行, 硬件比如神经网络能传播就行 (不要有 size 不匹配这种低级错误), 而不管软件、神经网络输出结果对不对.</p></li>
</ul>
</section>
</section>
<section id="open-source-tools" class="level2">
<h2 class="anchored" data-anchor-id="open-source-tools">Open Source Tools</h2>
<blockquote class="blockquote">
<p>该项目重度使用了以下开源项目, FPGA 开源是一个很大的工程, 感谢所有开源者!</p>
</blockquote>
<ul>
<li><p><a href="https://github.com/verilator/verilator"><strong>verilator</strong></a>: 允许你用 C++ 写 testbench (比用 <code>.v</code> 写方便太多), 然后将 verilog RTL 连同 testbench 一起转化为 C++ 代码, 在 CPU 上编译运行这个代码就相当于进行了仿真, 可模拟出时钟、寄存器逻辑、外设交互等行为 (注意 <code>verilator</code> 不同于 <code>Modelsim</code>, 并没有内置仿真器, 只是转为 C++, 实际仿真还是 gcc 跑的), 用法:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ls</span> <span class="co"># 确保有 blink.v 和 tb_blink.cpp</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="ex">verilator</span> <span class="at">-Wall</span> <span class="at">--trace</span> <span class="at">-cc</span> blink.v <span class="at">--exe</span> tb_blink.cpp <span class="co"># 会生成 ./obj_dir/, 其中含有转换好的很多 C++ 文件和 Vblink.mk</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">make</span> <span class="at">-C</span> obj_dir <span class="at">-f</span> Vblink.mk Vblink <span class="co"># -C 指 make 工作目录, 会生成 ./obj_dir/Vblink 可执行文件</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="ex">./obj_dir/Vblink</span> <span class="co"># 运行仿真, 会生成波形文件 ./waveform.vcd</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="ex">gtkwave</span> waveform.vcd <span class="co"># 用 GTKWave 查看波形</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><strong>VCS (Verilog Compiler Simulator)</strong>: 功能和用法跟 <code>verilator</code> 一模一样, 只不过是闭源的 (Synopsys 公司的商业仿真器).</li>
</ul></li>
<li><p><a href="https://www.cocotb.org"><strong>Cocotb</strong></a>: 一个 Python 库, 允许你用 Python 来写 testbench! 注意与 <code>verilator</code> 和 <code>icarus</code> 不同, <code>Cocotb</code> 在它们之上调用它们 (相当于 <code>verilator</code> 的前端), 用于方便地<strong>写测试逻辑</strong>而不是模拟硬件.</p></li>
<li><p><a href="https://github.com/steveicarus/iverilog"><strong>iverilog (Icarus Verilog)</strong></a>: 可直接输出波形的真正的仿真器 (不输出 C 代码). 由于是解释型的, 速度比 <code>verilator</code> 慢很多. 用法:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">iverilog</span> <span class="at">-o</span> blink.vvp blink.v blink_tb.v</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 生成 vcd 文件可配合 GTKWave 查看波形</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="ex">vvp</span> blink.vvp</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><a href="https://github.com/trabucayre/openFPGALoader"><strong>openFPGALoader</strong></a>: 用于将比特流烧录到 FPGA (但不能调试).</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 示例：</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="ex">openFPGALoader</span> <span class="at">-b</span> arty arty_bitstream.bit      <span class="co"># SRAM 加载</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="ex">openFPGALoader</span> <span class="at">-b</span> arty <span class="at">-f</span> arty_bitstream.bit   <span class="co"># 写入 flash</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><a href="https://github.com/openocd-org/openocd"><strong>openocd</strong></a>: Open On-Chip Debugger. 用于调试 FPGA 的工具. 支持 JTAG 接口.</p></li>
<li><p>三个端到端的工具链:</p>
<ul>
<li><p><strong>Vivado</strong>: IDE, 闭源.</p></li>
<li><p><a href="https://github.com/YosysHQ"><strong>yosysHQ (Yosys Open SYnthesis Suite Headquarters)</strong></a>: yyds!! 一个开源的 EDA 工具链. 子项目包括:</p>
<ul>
<li><p><a href="https://github.com/YosysHQ/icestorm"><strong>icestorm</strong></a>: 用于针对 Lattice iCE40 FPGA 实现完全的端到端开源流程, 从 Verilog 到 bitstream, 再烧写到 FPGA 板卡上. 以下每一个命令都是一个单独的 repo!!</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># yosys 综合 (将 verilog 转换为网表 .json)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="ex">yosys</span> <span class="at">-p</span> <span class="st">'synth_ice40 -top blink -json blink.json'</span> blink.v</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># nextpnr 布局布线 (生成 bitstream 的中间文件 .asc)</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="ex">nextpnr-ice40</span> <span class="at">--up5k</span> <span class="at">--json</span> blink.json <span class="at">--pcf</span> blink.pcf <span class="at">--asc</span> blink.asc</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># icepack 打包 (生成 bitstream .bin)</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="ex">icepack</span> blink.asc blink.bin</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># icesprog 烧写 (将 bitstream 写入 FPGA)</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> icesprog blink.bin</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul></li>
<li><p><a href="https://github.com/chipsalliance/f4pga"><strong>F4PGA</strong></a>: 以前叫 <code>Symbiflow</code>, 旨在为多家 FPGA 供应商 (Xilinx 7 系列、Lattice iCE40/ECP5、QuickLogic EOS S3 等) 提供统一、功能完备、可扩展且无需专有软件的端到端开发流程.</p>
<ul>
<li>里面大量使用了 <code>YosysHQ</code> 的工具.</li>
</ul></li>
</ul></li>
<li><p><a href="https://github.com/SpinalHDL"><strong>SpinalHDL</strong></a>: 一个基于 Scala 的硬件描述语言 (HDL), 用于生成 Verilog 代码. SpinalHDL 提供了更高级的抽象和更强大的功能, 使得硬件设计更加灵活和可扩展.</p>
<ul>
<li><a href="https://github.com/SpinalHDL/VexRiscv"><strong>VexRiscv</strong></a>:</li>
</ul></li>
<li><p><a href="https://github.com/enjoy-digital/litex"><strong>Litex</strong></a>: 支持用 Python 脚本拼装出完整的 SoC.</p></li>
<li><p><a href="https://fusesoc.readthedocs.io/en/stable/user/overview.html"><strong>FuseSoC</strong></a>: 用来描述和管理 IP 的工具.</p></li>
<li><p><a href="https://srecord.sourceforge.net/"><strong>SRecord</strong></a>: 一套命令行工具, 简单理解为将 <code>.elf</code> 文件转换为 <code>.hex</code> 或 <code>.bin</code> 文件的工具. 比如:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ex">srec_cat</span> input.elf <span class="at">-o</span> output.hex <span class="at">-intel</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
</section>
<section id="sec-eda-terms" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-eda-terms">EDA Terms</h2>
<ul>
<li><p><strong>AIEDA (MLDA/EDI/EDA2.0)</strong>: 利用 AI 来辅助 EDA 设计流程.</p></li>
<li><p><strong>Netlist 网表</strong>: 一个 Graph, 描述了电路用了哪些元件和它们之间的连接.</p>
<ul>
<li>Gate-level 门级网表: 比如用 <code>yosys</code> 生成的 <code>.json</code> 文件.</li>
<li>Transistor-level 晶体管级网表: <code>.spice</code>, <code>.cir</code>.</li>
</ul></li>
<li><p><strong>Fan-in 扇入</strong>: 连接到 pin <span class="math inline">\(v_i \in V\)</span> 的 pin 集合称为 <span class="math inline">\(v_i\)</span> 的 fan-in, 记为 <span class="math inline">\(\mathcal{F}(v_i)\)</span> <span class="citation" data-cites="liao_2023_dreamplace"><a href="#ref-liao_2023_dreamplace" role="doc-biblioref">[3]</a></span>.</p>
<ul>
<li><strong>Fan-out 扇出</strong> <a href="#fig-fan-in-out" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-fan-in-out</span></a>.</li>
</ul></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<div id="fig-fan-in-out" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fan-in-out-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fan-in-out.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fan-in-out-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: <span class="math inline">\(v_i\)</span> 节点有 <span class="math inline">\(3\)</span> 个 Fan-in 节点 和 <span class="math inline">\(2\)</span> 个 Fan-out 节点
</figcaption>
</figure>
</div>
</div></div><ul>
<li><p><strong>LEF (Library Exchange Format)</strong>: 描述 cell 的物理信息 (尺寸、形状、pin 位置、所在金属层, etc.)</p></li>
<li><p><strong>DEF (Design Exchange Format)</strong>: 描述整个芯片的 placement 和 routing.</p></li>
<li><p><strong>Bookshelf</strong>: 一套用于 VLSI 设计的开源文件格式, 包括:</p>
<ul>
<li><strong><code>.nodes</code></strong>: 描述 cell 的尺寸和类型.</li>
<li><strong><code>.pl</code></strong>: 描述 cell 的 placement.</li>
<li><strong><code>.nets</code></strong>: 描述 cell 之间的连接关系.</li>
<li><strong><code>.scl</code></strong>: 描述 row.</li>
</ul></li>
<li><p><strong>CSR (Compressed Sparse Row)</strong>: 用 index + data 进行<strong>连续</strong>存储的格式 (E.g., sparse matrix, <a href="../eda-3d-placement/eda-3d-placement.qmd">pin-list 表示法</a>, etc.)</p></li>
</ul>
<div class="quarto-layout-panel" data-layout="[50,50]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-sparse-matrix" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sparse-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="sparse-matrix.png" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sparse-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Sparse matrix 原始形式
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-sparse-matrix-csr" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sparse-matrix-csr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="sparse-matrix-csr.png" class="img-fluid figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sparse-matrix-csr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Sparse matrix 可以用三个数组来储存
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<ul>
<li>Transistor Architectures: 通过改变晶体管的<strong>物理构造</strong> (但基本原理不变!), 主要为了解决在<strong>沟道尺寸减小</strong>后的 <strong>Leakage current</strong> 问题.
<ul>
<li><strong>PlanarFET</strong>: 最传统的平面型晶体管, 沟道宽度极限 <span class="math inline">\(W_G = 20\text{ nm}\)</span> (N20/20N, 见 <a href="#fig-planar" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-planar</span></a>).</li>
<li><strong>FinFET</strong>: 鳍式场效应管. <span class="math inline">\(W_G = 3\text{ nm}\)</span> (N3). 2011 年 Intel 首次量产 FinFET 工艺. 2015 年, TSMC (N16), Samsung (N14) 也开始量产 FinFET.</li>
<li><strong>GAAFET (Gate-All-Around)</strong>: 栅极全环绕晶体管, 亦称 <strong>MBC-FET (Samsung), Nanosheet-FET (TSMC), Ribbon-FET (Intel)</strong>. 从 N2 开始将全面取代 FinFET. 可以向 <span class="math inline">\(z\)</span> 方向堆叠纳米片 (nanosheet), 而不需要像 FinFET 只能横着长 fin 鳞片, 可以提升 PPA.
<ul>
<li><strong>Intel 18A</strong> 叠了 <span class="math inline">\(4\)</span> 片 nanosheet <span class="citation" data-cites="11075006"><a href="#ref-11075006" role="doc-biblioref">[4]</a></span>, TSMC 和 Samsung 初代只有 <span class="math inline">\(3\)</span> 片.</li>
</ul></li>
<li><strong>Forksheet-FET</strong>: 将 NMOS 和 PMOS 的 nanosheet 直接放在一起, 通过中间的介电质墙隔开.</li>
<li><strong>CFET (Complementary FET)</strong>: 直接将 PMOS 的 nanosheet 堆叠在 NMOS 的 nanosheet 上方, 这样面积直接减半.</li>
</ul></li>
</ul>
<div class="quarto-layout-panel" data-layout="[28,72]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 28.0%;justify-content: flex-start;">
<div id="fig-planar" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-planar-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="planar.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-planar-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: PlanarFET (Adapted from <span class="citation" data-cites="semiecosystem_2024_imec"><a href="#ref-semiecosystem_2024_imec" role="doc-biblioref">[5]</a></span>).
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 72.0%;justify-content: flex-start;">
<div id="fig-tranarch" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tranarch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tranarch.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tranarch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Transistor architecture 的后续发展 <span class="citation" data-cites="verschueren_2017_outer"><a href="#ref-verschueren_2017_outer" role="doc-biblioref">[6]</a></span>. CH: Cell height, CPP: Contacted Poly Pitch
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<ul>
<li><strong>Power delivery network (PDN)</strong>: 电源分配网络.
<ul>
<li><strong>Backside power delivery (BSPD)</strong>: 通过芯片背面供电 (而不是跟信号线在同一侧)</li>
</ul>
<div id="fig-bspd" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bspd-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="bspd.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bspd-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: BSPD 示意图 <span class="citation" data-cites="Hossen2020PowerDN"><a href="#ref-Hossen2020PowerDN" role="doc-biblioref">[7]</a></span>.
</figcaption>
</figure>
</div></li>
</ul>
<section id="packaging-封装" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="packaging-封装">Packaging 封装</h3>
<ul>
<li><strong>Wafer 晶圆, Die, Chiplet Arch</strong>
<ul>
<li>Die 和 Tile: 一样的概念, 前者强调物理实体, 后者强调逻辑功能单元.</li>
</ul>
<div id="fig-chiplet" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-chiplet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="chiplet.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-chiplet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Wafer 是圆圆的一整块, 上面可以切下来 <span class="math inline">\(A,B,C,D\)</span> 四种不同的 die; Chiplet 思想 (Use smaller dies) 与其如何提高良率、降低成本 <span class="citation" data-cites="filho_2024_what"><a href="#ref-filho_2024_what" role="doc-biblioref">[8]</a></span>
</figcaption>
</figure>
</div></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<div id="fig-die2soc" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-die2soc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="die2soc.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-die2soc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: 多个 Die 通过 D2D connection (die-to-die) 形成 SoC <span class="citation" data-cites="filho_2024_what"><a href="#ref-filho_2024_what" role="doc-biblioref">[8]</a></span>
</figcaption>
</figure>
</div>
</div></div><ul>
<li><p><strong>3D IC</strong> 常见类型:</p>
<ul>
<li><strong>TSV-based</strong>: 用 <strong>TSV (Through-Silicon Via) 硅通孔</strong>, 就是在硅片上打孔, 然后在孔内镀铜, 形成垂直的电连接通道. 但由于 large pitches and parasitics, 性能提升有限 <span class="citation" data-cites="zhao2024analyticalheterogeneousdietodie3d"><a href="#ref-zhao2024analyticalheterogeneousdietodie3d" role="doc-biblioref">[9]</a></span>. <strong>BPV (Bond pad via)</strong> 可能类似 TSV <span class="citation" data-cites="10454441"><a href="#ref-10454441" role="doc-biblioref">[10]</a></span>?</li>
<li><strong>Monolithic</strong>: 一整块硅片上制造多个层次的电路, 成本高.</li>
<li><strong>F2F (Face-to-Face)</strong>: 用 <strong>HBT (Hybrid bonding terminal)</strong> (或 <strong>BPM (Bond pad metal)</strong> <span class="citation" data-cites="10454441"><a href="#ref-10454441" role="doc-biblioref">[10]</a></span>) 端子连接上下层 Die (通过直接原子键合) <span class="citation" data-cites="zhao2024analyticalheterogeneousdietodie3d"><a href="#ref-zhao2024analyticalheterogeneousdietodie3d" role="doc-biblioref">[9]</a></span>.</li>
</ul></li>
<li><p><strong>pitch 间距</strong>: 两个相邻的重复元件中心之间的距离. HBT 的优点就是 pitch 比较小 (fine), 集成度高.</p></li>
<li><p><strong>RSMTs (Rectilinear Steiner Minimal Trees)</strong>: 简单理解为 Manhattan 走线的最小生成树 (可以引入额外的 point 作为中间点, 称为 <strong>Steiner points</strong> <a href="#fig-steiner-pt" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-steiner-pt</span></a>, 原始给定的点一般是 pins).</p></li>
</ul>
<div class="quarto-layout-panel" data-layout="[60, -4, 36]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 60.0%;justify-content: flex-start;">
<div id="fig-steiner-pt" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-steiner-pt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="steiner-pt.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-steiner-pt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: 通过引入 Steiner point <span class="math inline">\(S\)</span> 可以减少线长
</figcaption>
</figure>
</div>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 4.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 36.0%;justify-content: flex-start;">
<div id="fig-num-steiner" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-num-steiner-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="num-steiner.png" class="img-fluid figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-num-steiner-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: <span class="math inline">\(\# \text{Steiner points} \le \# \text{pins} - 2\)</span>
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="placement-布局" class="level3">
<h3 class="anchored" data-anchor-id="placement-布局">Placement 布局</h3>
<ul>
<li><p><strong>HPWL (Half-Perimeter WireLength)</strong>: 某种线长的计算方法.</p></li>
<li><p><strong>Std cell, row, site, global placement, legalization, bin</strong>: 见 <a href="../eda-notes/eda-notes.html#sec-eda-terms">EDA Notes 笔记</a>.</p></li>
</ul>
</section>
<section id="timing-analysis" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="timing-analysis">Timing Analysis</h3>
<ul>
<li><p><strong>RC 提取</strong>: 从物理变量抽取电容、电阻.</p></li>
<li><p><strong>STA (Static Timing Analysis)</strong>: 静态时序分析 <span class="citation" data-cites="liao_2023_dreamplace"><a href="#ref-liao_2023_dreamplace" role="doc-biblioref">[3]</a></span>. 信号在导线上的传输是需要时间的. “Static” 指通过电路的电容、电阻算出电路的 delay (而不需要通过实际输入信号然后仿真).</p></li>
<li><p><strong>Timing arc</strong>: 若 pin <span class="math inline">\(i\)</span> 的信号变化会影响 pin <span class="math inline">\(j\)</span> 的信号变化, 则称 pin <span class="math inline">\(i\)</span> 到 pin <span class="math inline">\(j\)</span> 之间存在一个 timing arc (注意有方向).</p>
<ul>
<li><strong>Cell arc</strong>: 某个 cell (如 AND gate) 内部的 timing arc.</li>
<li><strong>Net/edge arc</strong>: 金属层走线或 via 上的 timing arc.</li>
<li><strong>Arc delay</strong>: 若 <span class="math inline">\((p_i, p_j)\)</span> 间存在 timing arc, 则 arc delay 表示从 pin <span class="math inline">\(p_i\)</span> 信号变化到 pin <span class="math inline">\(p_j\)</span> 信号变化所需的时间.</li>
<li><strong>Driver/source cell/pin (of a net <span class="math inline">\(e\)</span>)</strong>: <span class="math inline">\(e\)</span> 中没有箭头指向它的 cell/pin 集 (一定唯一, 见<a href="../eda-notes/eda-notes.html#fig-hypergraph">此图</a>) <span class="citation" data-cites="phdthesisAlgorithms2019"><a href="#ref-phdthesisAlgorithms2019" role="doc-biblioref">[11]</a></span>, 常记为 <span class="math inline">\(s(e)\)</span>.</li>
<li><strong>Sink cell/pin (of a net <span class="math inline">\(e\)</span>)</strong>: <span class="math inline">\(e\)</span> 中没有从它出发的箭头的 cell/pin 集 (可以不唯一) <span class="citation" data-cites="phdthesisAlgorithms2019"><a href="#ref-phdthesisAlgorithms2019" role="doc-biblioref">[11]</a></span>.</li>
</ul></li>
<li><p><strong>Slack (时序)裕量</strong>: Timing arc 不可避免, 但 arc delay 必须满足要求即可, 信号不能提前到 (<strong>Hold/early time violation</strong>), 也不能晚到 (<strong>Setup/late time violation</strong>)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. 即信号到达时间 AT (arrival time) 有一个 required 范围 (见 <a href="#fig-slack" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-slack</span></a>): <span class="math display">\[\operatorname{min} \text{RAT} \le \text{AT} \le \operatorname{max} \text{RAT}.\]</span></p>
<div id="fig-slack" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-slack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="slack.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-slack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: Slack 的定义. <span class="math inline">\(\text{slack} &gt; 0\)</span> 安全, <span class="math inline">\(\text{slack} &lt; 0\)</span> 违规 <span class="citation" data-cites="liao_2023_dreamplace"><a href="#ref-liao_2023_dreamplace" role="doc-biblioref">[3]</a></span>.
</figcaption>
</figure>
</div>
<ul>
<li><strong>WNS (Worst Negative Slack) <span class="math inline">\(s_{\text{wns}}\)</span></strong>: 违规里面的最坏 slack <span class="citation" data-cites="liao_2023_dreamplace"><a href="#ref-liao_2023_dreamplace" role="doc-biblioref">[3]</a></span> (如果没有违规, 则 <span class="math inline">\(s_{\text{wns}}\)</span> 不存在).</li>
<li><strong>TNS (Total Negative Slack) <span class="math inline">\(s_{\text{tns}}\)</span></strong>: 所有违规 slack 相加 <span class="citation" data-cites="liao_2023_dreamplace"><a href="#ref-liao_2023_dreamplace" role="doc-biblioref">[3]</a></span> (如果没有违规, 则 <span class="math inline">\(s_{\text{tns}}\)</span> 不存在).
<ul>
<li>一般 WNS 和 TNS 都只关心 Primary output endpoint pins (<strong>PO</strong>, 如 flip-flop inputs, outputs ports <span class="citation" data-cites="liao_2023_dreamplace"><a href="#ref-liao_2023_dreamplace" role="doc-biblioref">[3]</a></span>) 中的违规情况.</li>
</ul></li>
<li><strong>Critical path (CP)</strong>: 造成 WNS 的那条路径<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</li>
</ul></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;一般只考虑 Setup 违规, Hold 违规比较容易解决.</p></div><div id="fn2"><p><sup>2</sup>&nbsp;这个词在多个领域内都有使用 (比如项目管理中的 CPM), 总体来说想表达的就是「搅屎棍」的意思.</p></div></div><ul>
<li><strong>Buffer 缓冲器</strong>: 输入等于输出的逻辑门, 但是输入的 <code>1</code> 相当于引出电源的 <code>1</code>, 可以增强驱动. 还可以调节时延</li>
</ul>
</section>
</section>
<section id="ml-terms" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="ml-terms">ML Terms</h2>
<section id="general-terms-1" class="level3">
<h3 class="anchored" data-anchor-id="general-terms-1">General Terms</h3>
<ul>
<li><p>描述一个神经网络:</p>
<ul>
<li><strong>参数量</strong>: 模型中所有可训练参数的数量, 包括 weight 和 bias.
<ul>
<li>DeepSeek-R1 有 <span class="math inline">\(671\text{ B}\)</span> 可训练参数 (<span class="math inline">\(6710\)</span> 亿).</li>
</ul></li>
<li><strong>Activation 激活值</strong>: 神经网络各个层神经元上的数值 (注意与参数区分开!).</li>
<li><strong>Hyperparameter 超参数</strong>: 模型训练前需要设置的参数, 如学习率、batch size、层数, etc.</li>
</ul></li>
<li><p><strong>ANN (Artificial Neural Network)</strong>: 就是传统意义上的神经网络.</p></li>
<li><p><strong>MSE (Mean Squared Error)</strong>: 可用作 Loss function.</p></li>
<li><p><strong>AI 幻觉</strong>: AI 编造事实的现象.</p></li>
<li><p><strong>DAG (Directed Acyclic Graph) 计算图</strong>: 有向无环图, 用来可视化一次计算过程 (哪些数据先算, 后面的数据依赖哪些数据), 由张量和算子组成.</p></li>
<li><p><strong>NAS (Neural Architecture Search)</strong>: 神经网络架构搜索, 自动化地搜索神经网络的最佳架构 (而不是人工设计) <span class="citation" data-cites="mellor2021neuralarchitecturesearchtraining"><a href="#ref-mellor2021neuralarchitecturesearchtraining" role="doc-biblioref">[12]</a></span>.</p></li>
<li><p><strong>BIC (Brain-inspired Computing) / NM (Neuromorphic) Computing</strong>: 比如 SNN (Spiking Neural Network, 与 ANN 是同层概念).</p>
<ul>
<li><strong>ANN2SNN methods</strong>: 将 ANN 转换为 SNN 的方法 <span class="citation" data-cites="deng2025edgeintelligencespikingneural"><a href="#ref-deng2025edgeintelligencespikingneural" role="doc-biblioref">[13]</a></span>.</li>
<li><strong>EdgeSNN</strong>: “Edge Intelligence based on SNNs” <span class="citation" data-cites="deng2025edgeintelligencespikingneural"><a href="#ref-deng2025edgeintelligencespikingneural" role="doc-biblioref">[13]</a></span>.</li>
</ul></li>
<li><p><strong>Federated Learning</strong>: 为了避免公司不愿分享数据、用户隐私泄漏等问题, 将训练数据交付 cloud 不再可能, 所以我们先在边缘设备上训练模型, 然后用某种方法将各个边缘设备上学到的 “知识” 汇总到 cloud 上, 这就叫 <strong>FL</strong>. <span class="citation" data-cites="deng2025edgeintelligencespikingneural somvanshi2025tinymachinelearningtiny"><a href="#ref-deng2025edgeintelligencespikingneural" role="doc-biblioref">[13]</a>, <a href="#ref-somvanshi2025tinymachinelearningtiny" role="doc-biblioref">[14]</a></span></p></li>
</ul>
<div id="fig-ann-vs-snn" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ann-vs-snn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="ann-vs-snn.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ann-vs-snn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13: ANN vs SNN <span class="citation" data-cites="deng2025edgeintelligencespikingneural"><a href="#ref-deng2025edgeintelligencespikingneural" role="doc-biblioref">[13]</a></span>
</figcaption>
</figure>
</div>
<ul>
<li><p><strong>FM (Foundation Model)</strong>: 基础模型. 一般为了解决一个问题往往会训练一个专门的模型 (task-specific model). 但 FM 是一种通用的模型, 在大规模、广泛、多样的数据 (多模态的, 文字/图像/音频) 上进行预训练 (训练成本极高 <span class="citation" data-cites="tcheyan_2025_decentralized"><a href="#ref-tcheyan_2025_decentralized" role="doc-biblioref">[15]</a></span>); 然后可以通过微调 (fine-tuning) 来适应各种下游任务 (如文本生成、图像识别、语音识别等). 比如 Meta 的 Llama 模型.</p>
<ul>
<li><strong>Edge-native foundation models</strong>: 边缘化的 FM, 涉及到对大模型的 knowledge distillation, pruning, quantization 等技术, 以适应边缘设备的计算和存储限制 <span class="citation" data-cites="somvanshi2025tinymachinelearningtiny"><a href="#ref-somvanshi2025tinymachinelearningtiny" role="doc-biblioref">[14]</a></span>.</li>
</ul></li>
<li><p><strong>Pretraining 预训练</strong>: 用维基百科、书籍等未标注的大规模数据集对模型进行训练 (自监督的), 方法包括:</p>
<ul>
<li><strong>Masked Language Modeling (MLM)</strong>: 随机挖空, 然后预测挖空的词语.</li>
<li><strong>Next Sentence Prediction (NSP)</strong>: 以句子为单位的 MLM.</li>
</ul></li>
<li><p><strong>Post-training/Fine-tuning 后训练/微调</strong>: 在预训练模型的基础上, 用少量标注数据对模型进行训练, 以适应特定任务 (比如电影评论-&gt;情感标签).</p>
<ul>
<li><strong>Full fine-tuning 全参数微调</strong>: 会更新模型的<strong>所有</strong>参数. 性能好, 但成本极高 (700 亿参数的 LLM 需要 1TB 显存).</li>
<li><strong>Parameter-efficient fine-tuning (PEFT) 参数高效微调</strong>: 主流, 冻结 <span class="math inline">\(99\%\)</span> 以上的模型参数, 只更新少量参数 (E.g., LoRA).</li>
<li><strong>Instruction tuning/Supervised fine-tuning 指令微调/有监督微调 (SFT)</strong>: 用<strong>指令-回答对</strong>微调 <span class="citation" data-cites="tcheyan_2025_decentralized"><a href="#ref-tcheyan_2025_decentralized" role="doc-biblioref">[15]</a></span>, 如 “翻译成中文: How are you?” -&gt; “你好吗?”, 让模型会回答而只是文本补全.</li>
<li><strong>Alignment tuning/Reinforcement Learning with Human Feedback (RLHF) 对齐微调/基于人类反馈的强化学习</strong>: SFT 微调后的模型不是最有帮助的/有害的/不符合价值观的, RLHF 不是喂给模型更多数据, 而是让模型给出多个回答, 然后让<strong>人类</strong>打分 (Reward), 用强化学习 (如 PPO) 进行微调来最大化这个 Reward <span class="citation" data-cites="tcheyan_2025_decentralized"><a href="#ref-tcheyan_2025_decentralized" role="doc-biblioref">[15]</a></span>.</li>
</ul></li>
<li><p><strong>VLA (Vision Language Action)</strong>: 智能驾驶/机器人领域内的一种先进的多模态机器学习模型, 它结合了视觉、语言和动作三种能力, 旨在实现从感知输入直接映射到机器人控制动作的完整闭环能力.</p></li>
<li><p><strong>VLM (Vision Language Model)</strong>: 视觉语言模型, 可处理图片和自然语言两种模态进行理解和生成任务的模型.</p></li>
<li><p><strong>ViT (Vision Transformer)</strong>: 一种基于 Transformer 架构的计算机视觉模型.</p></li>
<li><p><strong>AIGC (AI-Generated Content)</strong>: 生成式 AI.</p></li>
</ul>
</section>
<section id="sec-cv-terms" class="level3">
<h3 class="anchored" data-anchor-id="sec-cv-terms">CV 计算机视觉相关</h3>
<ul>
<li><strong>Tensor</strong>: 多维数组.
<ul>
<li><p>名字来源: 由于数学里 <span class="math inline">\((0,k)\)</span>-tensor <span class="math inline">\(T: V^k \to \mathbb{F}\)</span> 在选取一组 basis <span class="math inline">\(\{\mathbf{e}_i\}_{i=1}^k\)</span> 后的 representation 刚好是一个 <span class="math inline">\(k\)</span> 维数组 <span class="math inline">\(T_{i_1i_2 \cdots i_k}\)</span> (正如 linear functional 可以被一个 covector 描述, bilinear functional 可以被一个 matrix 描述).</p></li>
<li><p>机器学习里 <strong>training data</strong>, <strong>kernel</strong>, <strong>feature map</strong> 等都用 tensor 来描述, Python 自带的 <code>list</code> 和 <code>np.array()</code>, 统统都要转化为 <code>torch.tensor</code>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># python list to tensor</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>data_list <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]]</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>list2tensor <span class="op">=</span> torch.tensor(data_list)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># numpy array to tensor</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>data_array <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]])</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>array2tensor <span class="op">=</span> torch.from_numpy(data_array)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Tensor Shape H, W, C(D), N</strong>: Height, Width, Channel(Depth), Batch size, 含义见 <a href="#fig-data-layout" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-data-layout</span></a>. 描述有一定顺序, 默认有两种:</p>
<ul>
<li><strong>Batch 在后</strong>: <u>HWC</u><strong>N</strong>.</li>
<li><strong>Batch 在前</strong>: <strong>N</strong><u>HWC</u>.</li>
</ul></li>
</ul></li>
<li><strong>Data Layout Formats 张量在内存中的布局</strong>
<ul>
<li><strong>NCHW</strong>: <code>pytorch</code></li>
<li><strong>NHWC</strong>: <code>numpy</code></li>
<li>TODO</li>
</ul>
<div id="fig-data-layout" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-data-layout-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="data-layout.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-data-layout-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14: 三种 Data Layout Formats <span class="citation" data-cites="a2023_understanding"><a href="#ref-a2023_understanding" role="doc-biblioref">[16]</a></span>.
</figcaption>
</figure>
</div></li>
<li><strong>Feature Map 特征图</strong>: CNN 中间层的一个 channel, 代表机器学习到的一种特征.
<ul>
<li>注意不是 kernel!</li>
<li><em>Abuse of Terms:</em> 有时 Input 的每个 channel 也叫 feature map.</li>
</ul>
<div id="fig-feature-map" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-feature-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="feature-map.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-feature-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15: 每个 kernel (filter) 可以产生一张 Feature map <span class="citation" data-cites="anello_2022_visualizing"><a href="#ref-anello_2022_visualizing" role="doc-biblioref">[17]</a></span>.
</figcaption>
</figure>
</div></li>
<li>一些图像处理工具:
<ul>
<li><strong>Pillow (<code>from PIL import Image</code>)</strong>: 一般用来对静态图像做基础操作 (裁剪、缩放、旋转、颜色变换等).</li>
<li><strong>OpenCV (<code>import cv2</code>)</strong>: 一般用来做视频流 (实时图像) 处理, 性能较高.</li>
<li><strong>FFmpeg (<code>import ffmpeg</code>)</strong>: 开源的命令行工具和 Python 库, 用来做音视频格式转换, 压缩等等还有很多, yyds.</li>
</ul></li>
</ul>
</section>
<section id="transformer-相关" class="level3">
<h3 class="anchored" data-anchor-id="transformer-相关">Transformer 相关</h3>
<ul>
<li><strong>Causal Self-attention</strong>: 给 attention 加上 mask (softmax 之前的 score 给 <span class="math inline">\(-\infty\)</span>), 使得每个 token 只能 attend 它前面的 token (包括它自己).</li>
</ul>
</section>
<section id="agent-相关" class="level3">
<h3 class="anchored" data-anchor-id="agent-相关">Agent 相关</h3>
<ul>
<li><strong>Agent Framework</strong>:
<ul>
<li><strong>Agent 智能体</strong>: 在 AI 模型和系统 Agent Tools (一些 API 比如 <code>read_files()</code>) 之间传话的程序.</li>
<li>User-agent 端: User 给出自然语言要求, Agent 理解并产生调用 API 的指令.
<ul>
<li><strong>User Prompt 用户提示词</strong>: 你问的问题 (自然语言).</li>
<li><strong>System Prompt 系统提示词</strong>: 系统给模型的隐藏指令, 一般用来改变 AI 的「人设」, 比如 “You are my girlfriend.”.
<ul>
<li><strong>Function Calling</strong>: 只是规范格式后的 System Prompt (比如用 <code>json</code>, 毕竟概率模型输出的指令可能不符合 API 要求).</li>
</ul></li>
</ul></li>
<li>Agent-API 端: Agent 调用 API (比如查找文件路径或者调用搜索引擎), 然后把结果返回给 Agent.
<ul>
<li><strong>MCP (Model Context Protocol)</strong>: 在 Agent 和 Agent Tools (API) 之间的一层, 方便整理不同类型的 Agent Tools.</li>
</ul></li>
</ul>
<div id="fig-agent-arch" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-agent-arch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="agent-arch.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-agent-arch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16: Agent Framework.
</figcaption>
</figure>
</div></li>
</ul>
</section>
<section id="computing-in-ml" class="level3">
<h3 class="anchored" data-anchor-id="computing-in-ml">Computing in ML</h3>
<ul>
<li><p><strong>Training/Inference 训练/推理</strong>: Training 是用数据集来更新模型参数的过程 (一般用 Backpropagation); Inference 是用训练好的模型来进行 Forward propagation 的过程 <span class="citation" data-cites="tcheyan_2025_decentralized"><a href="#ref-tcheyan_2025_decentralized" role="doc-biblioref">[15]</a></span>.</p>
<ul>
<li>Inference 比 Training 计算量小很多 (但是对大模型来说依然很大).</li>
<li>训练成本: 主要来自 GPU, 比如 NVIDIA H100/B200 costs $30K per unit <span class="citation" data-cites="tcheyan_2025_decentralized"><a href="#ref-tcheyan_2025_decentralized" role="doc-biblioref">[15]</a></span>, OpenAI 计划 2025 年底部署 100w 台 GPU! Altman 说 GPT-4 训练成本一亿美元.</li>
<li><strong>Decentralized/Distributed Training 分布式训练</strong>: Blockchain 的成功说明不同地方的算力可以 contribute to the same thing. 分布式训练目标是设计一个 blockchain-like system, 鼓励所有能联网的闲置设备贡献算力来训练大模型, 实现 <span class="math inline">\(0\)</span> GPU 成本. <span class="citation" data-cites="tcheyan_2025_decentralized dong2025singleaiclustersurvey"><a href="#ref-tcheyan_2025_decentralized" role="doc-biblioref">[15]</a>, <a href="#ref-dong2025singleaiclustersurvey" role="doc-biblioref">[18]</a></span>.
<ul>
<li><a href="https://www.primeintellect.ai/blog/protocol"><strong>Prime Intellect’s “Protocol”</strong></a> <span class="citation" data-cites="_2025_introducing"><a href="#ref-_2025_introducing" role="doc-biblioref">[19]</a></span>.</li>
</ul>
<div id="fig-third-epoch" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-third-epoch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="third-epoch.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-third-epoch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17: 分布式训练: The Third Epoch of AI <span class="citation" data-cites="_2025_chakra"><a href="#ref-_2025_chakra" role="doc-biblioref">[20]</a></span>.
</figcaption>
</figure>
</div></li>
</ul></li>
<li><p><strong>数据类型</strong>:</p>
<ul>
<li><strong>FP32</strong>: 32 位浮点数, 1 位符号位, 8 位指数位, 23 位尾数位, 精度高, 计算速度慢.</li>
<li><strong>BF16</strong>: Brain Floating Point 16, 1 位符号位, 8 位指数位, 7 位尾数位, 精度低, 计算速度快.</li>
</ul></li>
<li><p><strong>FLOP (Floating-Point OPeration)</strong>: 一次浮点运算包括一次加/减/乘/除.</p>
<ul>
<li><strong>FLOPs (Floating-point Operations)</strong>: 用来表达<strong>计算量</strong>.</li>
<li><strong>FLOPS (Floating-point Operations Per Second)</strong>: 用来表达<strong>算力</strong>
<ul>
<li><strong>OPS (Operations Per Second)</strong>: 一般是整数运算的算力单位.</li>
<li>比如 NVIDIA A10 FP32: <span class="math inline">\(31.2\)</span> TF (TeraFLOPS), INT8 有 <span class="math inline">\(250\)</span> TOPS | 500 TOPS* (稀疏模式下).</li>
</ul></li>
</ul></li>
<li><p><strong>MAC (Multiply‑ACcumulate)</strong>: <span class="math inline">\(a \leftarrow a + (b \times c)\)</span> 这种运算, 神经网络中有大量的 MAC 运算. 1 MAC = 2 FLOPs.</p>
<ul>
<li><code>torchprofile</code> 库可以统计模型中的 FLOPs 和 MACs.</li>
</ul></li>
<li><p><strong>Spase DNN</strong>: 稀疏神经网络, 指网络中有大量的权重为零 (即不参与计算) 的神经网络.</p>
<ul>
<li><p>根据稀疏的结构不同, 可分为三类 (见 <a href="#fig-sparsity" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-sparsity</span></a>). 其中 Semi-structured Sparsity 的意思是比如权重矩阵每 <span class="math inline">\(4\)</span> 个权重就有 <span class="math inline">\(2\)</span> 个权重为零 (记做 <span class="math inline">\(2:4\)</span> sparsity) <span class="citation" data-cites="sabih2025hardwaresoftwarecodesignriscvextensions"><a href="#ref-sabih2025hardwaresoftwarecodesignriscvextensions" role="doc-biblioref">[21]</a></span>.</p>
<div id="fig-sparsity" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sparsity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="sparsity.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sparsity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;18: 用权重矩阵展示 (a) Structured (b) unstructured (c) semi-structured sparsity <span class="citation" data-cites="sabih2025hardwaresoftwarecodesignriscvextensions"><a href="#ref-sabih2025hardwaresoftwarecodesignriscvextensions" role="doc-biblioref">[21]</a></span>, 蓝色的格子代表权重为 <span class="math inline">\(0\)</span>
</figcaption>
</figure>
</div></li>
<li><p><strong>Pruning</strong>: 剪枝, 将神经网络中不重要的权重 (如接近零的权重) 设置为零.</p>
<ul>
<li><strong>Unstructured Pruning</strong>: 非结构化剪枝, 移除个别权重, 硬件控制复杂度大.</li>
<li><strong>Structured Pruning</strong>: 结构化剪枝, 移除整个通道/滤波器/神经元等 <span class="citation" data-cites="sabih2025hardwaresoftwarecodesignriscvextensions"><a href="#ref-sabih2025hardwaresoftwarecodesignriscvextensions" role="doc-biblioref">[21]</a></span>, 更适合硬件加速. (比如 <a href="#fig-sparsity" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-sparsity</span></a> (a) 就可通过 pruning 移除输入的绿色神经元和输出的红色神经元).</li>
<li><strong>Semi-structured Pruning</strong>: 半结构化剪枝, 介于上述两者之间.</li>
</ul></li>
</ul></li>
<li><p><strong>Quantization 量化</strong>: 跟模数转换一样, 将模拟 (高分辨率, 如 FP32) 的数据转换为低分辨率 (如 INT8) 的过程.</p>
<ul>
<li><strong>量化方法</strong> (注意下面的概念不是严格并列的, 比如 Adaptive 量化可以是 Uniform 也可以是 Non-uniform) <span class="citation" data-cites="skki_2025_quantization"><a href="#ref-skki_2025_quantization" role="doc-biblioref">[22]</a></span>:
<ul>
<li><strong>Uniform 量化</strong></li>
<li><strong>Non-uniform 量化</strong></li>
<li><strong>Weight Clustering 权重聚类量化</strong></li>
<li><strong>Integer-only 纯整数量化</strong>: 将所有参数全部转化为整数 (而不是短的浮点如 DeepSeek 的 UE8M0 FP8), 如果有专门针对整数运算优化的硬件加速器就很适合.</li>
<li><strong>Hybrid 混合量化</strong></li>
<li><strong>Adaptive 自适应量化</strong></li>
</ul></li>
<li><strong>量化范式</strong> <span class="citation" data-cites="skki_2025_quantization"><a href="#ref-skki_2025_quantization" role="doc-biblioref">[22]</a></span>:
<ul>
<li><strong>PTQ (PQ, Post-Training Quantization) 训练后量化</strong>: 先完全不管量化将神经网络训练完成 (比如在 FP32 下训练), 然后在将其参数量化为低精度格式 (比如 INT8), 后续也不再训练了. 常见方法:
<ul>
<li><strong>ADPQ (ADaptive PQ)</strong>: 通过自适应 LASSO 回归识别敏感权重, 无需 Caliberation Dataset.</li>
<li><strong>GPTQ (GPT Quantization)</strong>: 给 GPT 量化的, 基于 Hessian 矩阵优化量化误差来压缩模型.</li>
<li><strong>SmoothQuant</strong>: 通过平滑激活值分布来减少量化误差.</li>
</ul></li>
<li><strong>QAT (Quantization-Aware Training) 量化感知训练</strong>: 在模型训练阶段就加入量化的训练让它学习到如何避免将来量化后精度损失 (比如前向传播时加入 fake quantization nodes 伪量化节点来模拟低精度的量化误差), 显然他肯定会比 PTQ 好, 但是训练成本很高. 常见方法:
<ul>
<li><strong>QLoRA</strong>: 结合了 <span class="math inline">\(4\)</span>-bit 量化和 LoRA 微调.</li>
<li><strong>AWQ (Activation-aware Weight Quantization)</strong>: 关注低精度量化 (INT4/INT3) 分析激活值分布, 优先保护对模型输出影响较大的权重, 适合边缘设备.</li>
</ul></li>
</ul></li>
</ul></li>
<li><p><strong>GEMM (GEneral Matrix-Matrix Multiplication)</strong>: 通用矩阵乘法.</p></li>
<li><p><strong>CIM (Compute In Memory)</strong>: 存内计算.</p></li>
<li><p><strong>Tiling 分块/瓦片</strong>: 在 CUDA 编程中, 由于 global memory 访问延迟高, 比如计算两个矩阵相加, 可以将上半和下半部分分别交给两个 block 里进行计算, 开辟两个 shared memory 来存储各自的半部分 (注意 shared memory 不在 block 间共享, 矩阵上下两半部分的相加刚好也是无依赖的! 如果是 GEMM 就不能这样分配!). shared memory 访问效率高.</p></li>
</ul>
</section>
<section id="optimizer-in-ml" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="optimizer-in-ml">Optimizer in ML</h3>
<ul>
<li><strong>Gradient Descent (GD) 梯度下降<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></strong>: 所有优化方法都从这个基础方法改进而来.
<ul>
<li><strong>Batch Gradient Descent (BGD) 全批量梯度下降</strong>: 用整个训练集计算梯度并更新参数.</li>
<li><strong>Stochastic Gradient Descent (SGD) 随机梯度下降</strong>: 每次用一个样本计算梯度并更新参数.</li>
<li><strong>Mini-batch Gradient Descent 小批量梯度下降</strong>: 每次用一批样本 (mini-batch, 如 <span class="math inline">\(32\)</span> 个样本) 前向传播然后算这批样本的平均 Loss 来进行反向传播更新参数.
<ul>
<li>前两个太极端了, BGD 计算量太大, SGD 不稳定, 基本不会用!</li>
</ul></li>
<li><strong>Batch</strong>: 每次用多少样本进行一次参数更新.
<ul>
<li><em>Abuse of Terms:</em> 有时候卷积核的个数也称为 batch (这是因为 image batch 和 kernel 在内存中的布局方法可以一样, 但真是离大谱!)</li>
</ul></li>
</ul></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;<em>Abuse of Terms:</em> 现在说的 GD/SGD 就是指 Mini-batch 版本! 实际训练中不用 BGD (计算量太大) 和纯 SGD (不稳定)!</p></div></div><ul>
<li><strong>Optimizer 优化器</strong>: 更新模型参数的算法.
<ul>
<li><strong>Momentum-based 动量优化器</strong>: 引入历史项的加权平均 (等价于指数加权), 相当于给参数中的点赋予质量和惯性 (而不是没有质量), 不易受噪声影响, 可<strong>加速</strong>和<strong>平滑</strong>收敛、避免<strong>陷入局部最优</strong><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. 也有一些基于次改良的版本:
<ul>
<li><p><strong>Nesterov Accelerated Gradient (NAG)</strong>: 将未来的参数点的梯度也参与计算, 避免 overshoot. 开启这个功能无需设置额外的超参数, 以 <code>torch</code> 为例:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>optimizer_nag <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>, momentum<span class="op">=</span><span class="fl">0.9</span>, nesterov<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul></li>
<li><strong>Adaptive Gradient (Adagrad) 自适应梯度优化器</strong>: 有利于 Sparse Features 的学习 (通过给每个参数分配不同的学习率! 或者理解为对参数进行归一化):</li>
</ul>
<div id="fig-adagrad" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-adagrad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="adagrad.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-adagrad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;19: Adagrad 给梯度平缓方向对应的参数 (<span class="math inline">\(Y\)</span>) 更大的学习率 (<span class="math inline">\(\alpha_Y = 0.05\)</span>) 来加快这个方向的下降 <span class="citation" data-cites="tg_2020_why"><a href="#ref-tg_2020_why" role="doc-biblioref">[24]</a></span>. 也可以用 “Normalize” 的角度理解.
</figcaption>
</figure>
</div></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;“SGD is a walking man downhill, slowly but steady. Momentum is a heavy ball running downhill, smooth and fast.” <span class="citation" data-cites="maciejbalawejder_2022_optimizers"><a href="#ref-maciejbalawejder_2022_optimizers" role="doc-biblioref">[23]</a></span></p></div></div></section>
<section id="ml-frameworks" class="level3">
<h3 class="anchored" data-anchor-id="ml-frameworks">ML Frameworks</h3>
<ul>
<li><p><strong>Tensorflow, JAX, PyTorch</strong>: 机器学习框架 <a href="#fig-mlsys" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-mlsys</span></a>. 其实就是一些 Python 库.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax.numpy <span class="im">as</span> jnp</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Pytorch 是最主流的, Tensorflow 快死了好像.</li>
<li>如何看待公司面试要求手写 transformer? 首先会背 Pytorch 函数并不 cool, Pytorch 只是复刻了主流论文里的框架, 如果你能写一个架构并且顶替 transformer, 你的库函数不久后也会出现在 Pytorch 里.</li>
<li>RISCV 上有 TfLM (TensorFlow Lite for Microcontrollers),</li>
<li><strong>ONNX (Open Neural Network Exchange)</strong>: 一种统一的描述神经网络结构的格式, 以上三种框架都支持导出为 ONNX 格式.</li>
</ul></li>
<li><p><strong>TVM, XLA (Accelerated Linear Algebra)</strong>: 机器学习编译器 <a href="#fig-mlsys" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-mlsys</span></a>, 在以上三个框架内都有 python 的接口函数.</p>
<ul>
<li><strong>OpenXLA</strong>: 中间表示 <strong>StableHLO (Stable High-Level Optimizer)</strong>, <strong>XLA</strong>, <strong>PJRT</strong> 的实现工程.</li>
</ul></li>
</ul>
<div id="fig-mlsys" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mlsys-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="mlsys.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mlsys-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20: AI 编译栈和编程体系
</figcaption>
</figure>
</div>
</section>
<section id="benchmarks-in-ml" class="level3">
<h3 class="anchored" data-anchor-id="benchmarks-in-ml">Benchmarks in ML</h3>
<ul>
<li><p><strong>AUC (Area Under Curve)</strong>: 二分类模型的性能评估指标, 越大越好.</p></li>
<li><p><strong>F-score</strong>: 二分类 (正类、负类) 模型的性能评估指标.</p>
<ul>
<li><p><strong>TP (True Positive)</strong>: 正类被正确分类为正类.</p></li>
<li><p><strong>FP (False Positive)</strong>: 负类被错误分类为正类.</p></li>
<li><p><strong>FN (False Negative)</strong>: 正类被错误分类为负类.</p></li>
<li><p><strong>Recall 召回率</strong>: <span class="math inline">\(TP/TP+FP\)</span></p></li>
<li><p><strong>Precision 精确率</strong>: <span class="math inline">\(TP/TP+FN\)</span></p></li>
<li><p><strong>F1-score</strong>: Recall 和 Precision 的调和平均 (F-<span class="math inline">\(\beta\)</span> score 的特例)</p></li>
<li><p><strong>F-<span class="math inline">\(\beta\)</span> score</strong>: 仅仅是给 recall 加了权重.</p>
<p><img src="F-score.png" class="img-fluid"></p></li>
</ul></li>
<li><p><strong>A/B Test</strong>: 类似双盲实验, 比如研究修改按钮颜色能否提升点击率? 新模型是否真的比旧模型好? 可以用这种方法进行对比实验.</p></li>
<li><p><strong>QE (Quantization Error) 量化误差</strong></p>
<ul>
<li><strong>AQE (Average Quantization Error) 平均量化误差</strong></li>
<li><strong>MQE (Maximum Quantization Error) 最大量化误差</strong></li>
<li><strong>OQE (Output Quantization Error) 输出层量化误差</strong></li>
</ul></li>
</ul>
</section>
<section id="related-philosophy" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="related-philosophy">Related Philosophy</h3>
<ul>
<li><strong>Symbol Grounded Problem</strong>: 符号嵌入 (接地) 问题. 探讨的是符号 (或词语) 是如何在一个系统中获得意义的. 比如 “猫” 是一个符号, 但它不仅仅是一个符号, 它还与其它符号有所关联 (Grounded “嵌入”), 这种关联是 “猫” 的意义. 关于符号是如何嵌入的, 有以下几种观点:
<ul>
<li><strong>具身认知</strong>: 意义必须通过一种感官、具身的方式与世界互动, 才能真正理解并嵌入符号. <span class="citation" data-cites="The_Human_Developers_2025_cnblogs"><a href="#ref-The_Human_Developers_2025_cnblogs" role="doc-biblioref">[25]</a></span></li>
<li><strong>联结主义</strong>: 符号的意义只取决于它与其它符号的关系 (有点范畴论的感觉哈哈). 符号可以通过网络中激活模式来进行嵌入. 这些模型并不明确地定义符号的意义, 而是通过训练大量数据, 学习感官输入与概念之间的关联. <span class="citation" data-cites="The_Human_Developers_2025_cnblogs"><a href="#ref-The_Human_Developers_2025_cnblogs" role="doc-biblioref">[25]</a></span></li>
</ul></li>
<li><strong>Inductive Bias (归纳偏见)</strong>: 人类通过先验知识和经验 (归纳) 来引导学习过程, 这个过程体现在: 给神经网络设计特定的结构、将自由度更大的模型的某些参数置 <span class="math inline">\(0\)</span> (将函数空间/参数空间减小, 比如 CNN 可以看作 FCNN 的子集 <a href="#fig-cnn-fcnn" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-cnn-fcnn</span></a>), etc. 这样可以, 但是可能人为地丢弃了结构很好的函数空间 (bias) <span class="citation" data-cites="battaglia2018relationalinductivebiasesdeep"><a href="#ref-battaglia2018relationalinductivebiasesdeep" role="doc-biblioref">[26]</a></span>.
<ul>
<li>Weak Inductive Bias 的网络 (比如 ViT, compared with CNN) 需要的训练数据更多 (data-hungry).</li>
<li>Advantage: 如果归纳地合适, 可以让模型更快地收敛到合理的解. 比如 <a href="#fig-different-ib" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-different-ib</span></a> 中我们用 <span class="math inline">\(5\)</span> 个参数的神经网络拟合两个<strong>斜抛运动</strong>的数据点. 如果事先告诉模型这是一个斜抛运动 (by setting weights <span class="math inline">\(w_1=w_2=w_5=0\)</span>), 而不是 exponential decay, 模型很容易就能拟合出很准确的结果 (棕色).</li>
<li>Disadvantage: 如果归纳地不合适, 比如 <a href="#fig-different-ib" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-different-ib</span></a> 的红色和紫色, 显然离斜抛运动差得远.
<ul>
<li>再拿 CNN 举例, 由于 CNN 在<strong>几乎每一层</strong>使用卷积核, 它隐含的 bias 就是: 一张图片的<strong>语义可以由局部的信息层次化拼凑出来</strong>、图片<strong>元素的位置不影响图片的语义 (平移不变性)</strong>. 这样训练出来的模型对于手写数字识别非常准确和高效, 但是会先入为主地重视局部纹理而不是全局特征 (<a href="#fig-colored-cat" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-colored-cat</span></a> 是一个很经典的例子, 说明 ViT 很好地解决了 CNN 很难学习到全局信息的问题).</li>
<li>但 ViT 也有自己的 bias: 比如<strong>切分成 patch 的时候引入了局部性</strong>、<strong>所有 patch 用同一个线性映射层 (shared embedding matrix) 也引入了平移不变性</strong>. 但是这只是在第一步编码时引入的, 后面位置编码和 transformer 就能很好地学习到全局信息了.</li>
</ul></li>
</ul></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<div id="fig-colored-cat" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-colored-cat-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="colored-cat.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-colored-cat-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21: Inductive Bias Demo. 一张彩色猫, ResNet 将其分类为 “金刚鹦鹉”, 而 ViT 分类为 “埃及猫” <span class="citation" data-cites="juliaturc_2025_why"><a href="#ref-juliaturc_2025_why" role="doc-biblioref">[27]</a></span>.
</figcaption>
</figure>
</div>
</div></div><div class="quarto-layout-panel" data-layout="[50,50]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-cnn-fcnn" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cnn-fcnn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="cnn-fcnn.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cnn-fcnn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22: CNN 是有归纳偏见的 FCNN (原本 <span class="math inline">\(64\)</span> 个参数减小到了 <span class="math inline">\(4\)</span> 个参数).
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-different-ib" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-different-ib-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="different-ib.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-different-ib-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;23: 不同的 Inductive Bias 带来完全不同的拟合效果 <span class="citation" data-cites="gerstnerlab_2023_rl36"><a href="#ref-gerstnerlab_2023_rl36" role="doc-biblioref">[28]</a></span>.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="pu-terms" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="pu-terms">PU Terms</h2>
<section id="cpu-terms" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="cpu-terms">CPU Terms</h3>
<ul>
<li><p><strong>PSR (Program Status Register)</strong>: 程序状态寄存器. 有 NZVC (Negative, Zero, Overflow, Carry) 四个标志位.</p></li>
<li><p><strong>Hart (Hardware Thread)</strong>: 硬件线程, 指一个独立的处理器核心, 包括一套流水线, 寄存器, PC 等等 (今后将不提处理器核心这个概念, 只提 Hart).</p></li>
<li><p><strong>Benchmark</strong>: 基准测试. 用于测试系统或工具的功能/性能.</p></li>
<li><p><strong>QEMU (Quick Emulator)</strong>: 开源的模拟器, 可模拟多种 CPU 架构 (如 ARM, x86, RISCV 等).</p></li>
<li><p><strong>Renode</strong>: 开源的模拟器, 主要面向嵌入式系统.</p></li>
<li><p><strong>Endianness</strong><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="endianness.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>大端与小端 <span class="citation" data-cites="Lazyparser_2025_bilibili"><a href="#ref-Lazyparser_2025_bilibili" role="doc-biblioref">[29]</a></span></figcaption>
</figure>
</div></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;记忆: 小端是自然的, 因为大部分人喜欢洗小头 (</p></div></div><ul>
<li><p><strong>MMU (Memory Management Unit)</strong>: 内存管理单元, 负责虚拟内存和物理内存之间的映射. 结合 UEFI+PCIe, 使得虽然地址总线宽度固定, 但 CPU 能访问的 ROM 和 RAM 却可以自由扩展!</p>
<ul>
<li><strong>TLB (Translation Lookaside Buffer)</strong>: 很像 CPU 的 Cache, 用于加速虚拟地址到物理地址的转换. 也有 TLB miss, TLB hit, spacial locality, temporal locality, etc. 这些概念.</li>
</ul></li>
<li><p><strong>PPA (Power, Performance, Area)</strong>: 三个重要的设计指标.</p></li>
<li><p><strong>DSA (Domain Specific Architecture)</strong></p></li>
</ul>
</section>
<section id="gpu-terms" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="gpu-terms">GPU Terms</h3>

<div class="no-row-height column-margin column-container"><div class="">
<div id="fig-amd-gpu-2015" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-amd-gpu-2015-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="amd-gpu-2015.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-amd-gpu-2015-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;24: AMD GPU 2015 采用 2.5D 封装.
</figcaption>
</figure>
</div>
</div></div><ul>
<li><strong>Kernel</strong>: 在 GPU 上运行的函数.</li>
</ul>
</section>
<section id="memory-存储器-terms" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="memory-存储器-terms">Memory 存储器 Terms</h3>
<ul>
<li><strong>DMA (Direct Memory Access)</strong>: 在不通过 CPU 的情况下, 外围设备直接和主内存进行数据传送.</li>
</ul>
<blockquote class="blockquote">
<p>以下从高速到低速介绍 (近 CPU 到远 CPU, GPU 几乎是一样的).</p>
</blockquote>
<ul>
<li><strong>Register 寄存器</strong> (物理介质: 高速 SRAM):
<ul>
<li><strong>GPRs (General Purpose Registers)</strong>: GPR 有专门的名字访问指令, 不是通过 memory map 来访问的!</li>
<li><strong>CSRs (Control and Status Registers)</strong>: 控制状态寄存器, 也有专门的名字访问指令, 也不是通过 memory map 来访问的!</li>
</ul></li>
<li><strong>TCM (Tightly Coupled Memory)</strong> (物理介质: SRAM):
<ul>
<li><p>由于 Cache 访问时间是<strong>无法控制</strong>的 (因为 Cache 中的数据是动态更新的, 会根据一定算法 (如 tree-PLRU) 淘汰和保留, 可能会出现 Cache miss), 在很多实时系统中, 这种 miss 会带来<strong>不可预测</strong>的延迟. 如果有经常访问的数据 比如 <code>sensor_data</code>, TCM 允许程序员显式地将其放在 TCM 中 (假设 <code>.dtcm</code> 在 linker script 里面定义过) (这样访问时间是<strong>可预测</strong>的):</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode c code-with-copy"><code class="sourceCode c"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> sensor_data<span class="op">[</span><span class="dv">1024</span><span class="op">]</span> __attribute__<span class="op">((</span>section<span class="op">(</span><span class="st">".dtcm"</span><span class="op">)));</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>TCM 会被分配固定独立的地址空间 (通过 linker file <code>.ld</code> 定义, 后续通过 memory map 访问!), 而且会有模块检测访存的地址是否在 TCM 范围内, 如果是则会通过专用的 TCM 总线访问!</p></li>
<li><p><strong>DTCM, ITCM (Data TCM)</strong>: 存放数据 Data 和 指令 Instruction 的 TCM. 它们在 Google Coral NPU 中被分配以下地址空间 <span class="citation" data-cites="googlecoral_2025_github"><a href="#ref-googlecoral_2025_github" role="doc-biblioref">[30]</a></span>:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>coralnpu_tcm.ld</strong></pre>
</div>
<div class="sourceCode" id="lst-coralnpu-tcm-ld" data-filename="coralnpu_tcm.ld"><pre class="sourceCode c code-with-copy"><code class="sourceCode c"><span id="lst-coralnpu-tcm-ld-1"><a href="#lst-coralnpu-tcm-ld-1" aria-hidden="true" tabindex="-1"></a>MEMORY <span class="op">{</span></span>
<span id="lst-coralnpu-tcm-ld-2"><a href="#lst-coralnpu-tcm-ld-2" aria-hidden="true" tabindex="-1"></a>    ITCM<span class="op">(</span>rx<span class="op">):</span> ORIGIN <span class="op">=</span> <span class="bn">0x00000000</span><span class="op">,</span> LENGTH <span class="op">=</span> <span class="dv">8</span><span class="er">K</span></span>
<span id="lst-coralnpu-tcm-ld-3"><a href="#lst-coralnpu-tcm-ld-3" aria-hidden="true" tabindex="-1"></a>    DTCM<span class="op">(</span>rx<span class="op">):</span> ORIGIN <span class="op">=</span> <span class="bn">0x00010000</span><span class="op">,</span> LENGTH <span class="op">=</span> <span class="dv">32</span><span class="er">K</span></span>
<span id="lst-coralnpu-tcm-ld-4"><a href="#lst-coralnpu-tcm-ld-4" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
</ul></li>
<li><strong>Cache 缓存</strong> (物理介质: SRAM):
<ul>
<li>因与 “cash” 同音, 常记为 “$”.</li>
<li>注意 Cache 没有分配独立的地址空间, 在 CPU 和 RAM 间是「透明」的!</li>
<li><strong>L1D$, L1I$</strong>: 一级数据缓存和一级指令缓存<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</li>
</ul></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;区分 D$/DTCM, I$/ITCM: 有没有独立地址空间 (是否「透明」)、访问是否可预测. 但有的地方会混用这两个概念!</p></div></div><ul>
<li>RAM (物理介质: DRAM):
<ul>
<li>CPU RAM, 具体的技术包括:
<ul>
<li><strong>DDR (Double Data Rate)</strong>: 一种 (双倍数据率) CPU RAM, 在上升沿和下降沿各传输一次数据. <strong>SDR</strong> 是早期内存技术, 只在时钟上升沿传输数据.</li>
</ul></li>
<li>GPU RAM (<strong>VRAM</strong> (Video)), 具体的技术包括:
<ul>
<li><strong>GDDR (Graphics DDR)</strong>: 显存 (每颗 GDDR6X 带宽 <span class="math inline">\(80\)</span> GB/s.)</li>
<li><strong>HBM (High Bandwidth Memory)</strong>: 高带宽内存 (每颗 HBM2E 带宽 <span class="math inline">\(460\)</span> GB/s.)</li>
</ul></li>
</ul></li>
<li>ROM (物理介质: Flash):
<ul>
<li>会被分配固定的地址空间.</li>
<li><strong>SSD (Solid State Drive)</strong>: 硬盘, 上面有很多 flash 芯片 + 接口协议 (SATA, M.2, etc.) 控制电路.</li>
<li><strong>Boot ROM</strong>: 存放启动代码的 ROM (固定独立地址空间, memory map 访问), 上电后 CPU 会把这里的代码加载到 RAM 并 jump 过去开机.</li>
</ul></li>
<li><strong>物理存储介质</strong>: 上面说的都是逻辑上的存储器, 下面讲实际上存储数据的物理介质.
<ul>
<li><strong>SRAM (Static RAM)</strong>: 寄存器、Cache、TCM.</li>
<li><strong>DRAM (Dynamic RAM)</strong>: 主内存.</li>
<li><strong>Flash</strong>: ROM</li>
</ul></li>
</ul>
</section>
</section>
<section id="riscv" class="level2">
<h2 class="anchored" data-anchor-id="riscv">RISCV</h2>
<ul>
<li><p><strong>ABI (Abstract Binary Interface)</strong>: 抽象二进制接口. 比如寄存器的使用约定 (比如函数传参用 <code>a0~a7</code>), 数据类型大小 (char 占几个字节等), 函数调用约定, 内存对齐等.</p></li>
<li><p><strong>Hart (Hardware Thread)</strong>: 硬件线程, 指一个独立的处理器核心, 包括一套流水线, 寄存器, PC 等等 (今后将不提处理器核心这个概念, 只提 Hart).</p></li>
<li><p><strong>PMP (Physical Memory Protection)</strong>: 物理内存保护.</p></li>
<li><p><strong>RVV (RISCV Vector Extension)</strong>: RISCV 向量扩展.</p></li>
</ul>
</section>
<section id="c-compile-terms" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="c-compile-terms">C Compile Terms</h2>
<ul>
<li><p><strong>gcc (GNU Compiler Collection)</strong>: GNU 编译器集合, 包括 C、C++、Go 等编程语言的编译器.</p>
<ul>
<li>gcc = clang (前端) + LLVM (后端) (在功能上)</li>
</ul></li>
<li><p><strong>IR (Intermediate Representation)</strong>: 编译器在编译过程中形成的中间代码 (不一定只有一层, 可以有多层), 用于编译器优化和代码生成.</p>
<ul>
<li><strong>GIMPLE</strong>: gcc 生成的中间表示</li>
<li><strong>LLVM IR</strong>: clang 生成的中间表示</li>
</ul></li>
<li><p><strong>MLIR (Multi-level IR)</strong>: 机器学习模型训练的中间表示.</p></li>
<li><p><strong>StableHLO (Stable High-Level Optimizer)</strong>: 也是机器学习的中间表示.</p></li>
<li><p><strong>GDB (GNU Debugger)</strong>: GNU 调试器. 支持 Assembly, C/C++, Go, Rust 等.</p></li>
<li><p><strong>elf (Executable Linkable Format)</strong>: 可执行链接格式. 包含 <code>.o</code>, <code>a.out</code>, <code>.so</code> 等文件.</p>
<ul>
<li><strong>Binutils (Binary Utilities)</strong>: elf 文件处理相关工具, 包括:
<ul>
<li><code>objdump</code>: 反汇编工具.</li>
<li><code>objcopy</code>: 执行文件格式转换. elf 中还包含了很多运行时不需要的信息, <code>objcopy</code> 可将这些信息去掉生成 <code>bin</code> 文件.</li>
<li><code>readelf</code>: 显示更多 elf 格式文件的信息.</li>
<li><code>ar</code>: tar, 将多个文件打包成一个大文件.</li>
</ul></li>
</ul></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="elf-format.png" class="img-fluid figure-img"></p>
<figcaption>ELF 文件格式 <span class="citation" data-cites="Lazyparser_2025_bilibili"><a href="#ref-Lazyparser_2025_bilibili" role="doc-biblioref">[29]</a></span></figcaption>
</figure>
</div>
</div></div><ul>
<li><strong>Cross Compilation</strong>: 交叉编译, 即在另一台机器上面开发手里面的这台机器 (嵌入式开发, 或在 MacOS 编写 RISCV 的操作系统).
<ul>
<li>构建 (build) 系统: 生成可执行程序的计算机.</li>
<li>主机 (host) 系统: 运行可执行程序的计算机.</li>
<li>目标 (target) 系统: 可执行程序运行的计算机架构</li>
</ul></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cross-compilation.png" class="img-fluid figure-img"></p>
<figcaption>交叉编译</figcaption>
</figure>
</div>
</div></div><ul>
<li><p><strong>Intrinsic 内联</strong>: 将汇编代码嵌入到 <code>C/C++</code> 代码中. 比如在想在 <code>C++</code> 中嵌入 RVV 汇编代码, 可以先 <code>#include &lt;riscv_vector.h&gt;</code> 头文件, 然后就可以这样用:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="dt">size_t</span> vl <span class="op">=</span> __riscv_vsetvlmax_e32m1<span class="op">();</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
</section>
<section id="operating-system-terms" class="level2">
<h2 class="anchored" data-anchor-id="operating-system-terms">Operating System Terms</h2>
<ul>
<li><strong>RTOS (Real-Time Operating System)</strong>: 实时操作系统, 用于嵌入式系统.
<ul>
<li><strong>FreeRTOS</strong>: 设计小巧, 核心代码只有 3 到 4 个 C 文件, 支持 ARM, x86, RISCV <span class="citation" data-cites="Lazyparser_2025_bilibili"><a href="#ref-Lazyparser_2025_bilibili" role="doc-biblioref">[29]</a></span>.</li>
<li><strong>RT-Thread</strong>: 也是一个 RTOS</li>
</ul></li>
</ul>
</section>
<section id="ysyx-terms" class="level2">
<h2 class="anchored" data-anchor-id="ysyx-terms">YSYX Terms</h2>
<ul>
<li><p><strong>AM (Abstraction Machine)</strong>: 抽象机, 用程序模拟的硬件计算机.</p></li>
<li><p><strong>NPC (New Processor Core)</strong>: 指我们自己设计的处理器.</p></li>
</ul>
</section>
<section id="integrated-circuit-terms" class="level2">
<h2 class="anchored" data-anchor-id="integrated-circuit-terms">Integrated Circuit Terms</h2>
<ul>
<li><strong>VLSI (Very Large Scale Integration)</strong>: 超大规模集成电路.</li>
<li><strong>RGCN (Relational Graph Convolutional Network)</strong>: 关系图卷积网络.</li>
</ul>
</section>
<section id="optimization" class="level2">
<h2 class="anchored" data-anchor-id="optimization">Optimization</h2>
<ul>
<li><p><strong>TSP (Travelling Salesman Problem)</strong>: 旅行商问题. 给定若干城市与它们之间的距离, 目标是找出一条路径, 使旅行者每个城市恰好访问一次, 最终回到起点, 并且总旅行距离最短.</p></li>
<li><p><strong>CVRP (Capacitated Vehicle Routing Problem)</strong>: 带容量限制的车辆路径问题. 多辆车运送货物给多个城市, 每辆车只能装有限重量的货物, 目标是货物全送到并让运送距离最短.</p></li>
<li><p><strong>FFSP (Flexible Flow Shop Problem)</strong>: 灵活流水车间调度问题.</p>
<div id="fig-ffsp" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ffsp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="ffsp.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ffsp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;25: FFSP
</figcaption>
</figure>
</div></li>
</ul>
<!-- ## AnalogGYM Terms

- **FOM (Figure of Merit)**: 性能指标.

- **PVT (Process, Voltage, Temperature)**: 影响电路性能的三个主要因素.
    - **Process**: 工艺, e.g.,
        - TT (Typical-Typical): 典型工艺角, NMOS 和 PMOS 都是典型速度设计的目标工艺角
        - FF (Fast-Fast): 快-快工艺角, NMOS 和 PMOS 都比典型值快, 功耗通常较高，速度快
        - SS (Slow-Slow): 慢-慢工艺角, NMOS 和 PMOS 都比典型值慢, 功耗较低，但速度慢
        - FS (Fast-Slow): 快-慢工艺角, NMOS 快，PMOS 慢, 不对称的工艺条件
        - SF (Slow-Fast): 慢-快工艺角, NMOS 慢，PMOS 快, 另一种不对称条件NMOS慢，PMOS快
    - **PVT corner**: PVT 角, 某种特定的工艺、电压和温度组合 (一般是比较极端的组合, 所以称为 "corner").
    
- **GAT (Graph Attention Network)**: 图注意力网络.

- **MTRL (Multi-task Reinforcement Learning)**: 多任务强化学习.

- **PDK (Process Development Kit)**: 工艺开发套件.
    - **NDA (Non-Disclosure Agreement)**: 商业 PDK 必须对模型文件、器件参数、仿真结果保密 (这是将 ML 应用于电路设计的最大瓶颈之一 @li_2023_design).
    - **SKY130**: 开源 PDK, 由 Google 和 SkyWater Technology 在 2020 年共同开发的 130nm 开源工艺平台. -->
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>


<div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-sali2025realtimefpgabased" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">S. M. Sali, M. Meribout, and A. A. Majeed, <span>“Real time FPGA based CNNs for detection, classification, and tracking in autonomous systems: State of the art designs and optimizations.”</span> 2025. Available: <a href="https://arxiv.org/abs/2509.04153">https://arxiv.org/abs/2509.04153</a></div>
</div>
<div id="ref-Simulation_Time._Putting_2025_oscc" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">YSYX, <span>“E5 从 RTL 代码到可流片版图 | 官方文档,”</span> 2025, Available: <a href="https://ysyx.oscc.cc/docs/2407/e/5.html">https://ysyx.oscc.cc/docs/2407/e/5.html</a></div>
</div>
<div id="ref-liao_2023_dreamplace" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">P. Liao, D. Guo, Z. Guo, S. Liu, Y. Lin, and B. Yu, <span>“DREAMPlace 4.0: Timing-driven placement with momentum-based net weighting and lagrangian-based refinement,”</span> <em>IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</em>, vol. 42, pp. 3374–3387, Jan. 2023, doi: <a href="https://doi.org/10.1109/tcad.2023.3240132">10.1109/tcad.2023.3240132</a></div>
</div>
<div id="ref-11075006" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">K. Fischer <em>et al.</em>, <span>“Intel 18A platform technology featuring RibbonFET (GAA) and PowerVia for advanced high-performance computing,”</span> in <em>2025 symposium on VLSI technology and circuits (VLSI technology and circuits)</em>, 2025, pp. 1–3. doi: <a href="https://doi.org/10.23919/VLSITechnologyandCir65189.2025.11075006">10.23919/VLSITechnologyandCir65189.2025.11075006</a></div>
</div>
<div id="ref-semiecosystem_2024_imec" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Semiecosystem, <span>“Imec, TSMC, samsung-IBM make progress with CFETs.”</span> Substack.com; Semiecosystem, Dec. 2024. Available: <a href="https://marklapedus.substack.com/p/imec-tsmc-samsung-ibm-make-progress">https://marklapedus.substack.com/p/imec-tsmc-samsung-ibm-make-progress</a>. [Accessed: Dec. 07, 2025]</div>
</div>
<div id="ref-verschueren_2017_outer" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">L. Verschueren and G. Hellings, <span>“Outer wall forksheet: Bridging nanosheet and CFET | imec.”</span> Imec, 2017. Available: <a href="https://www.imec-int.com/en/articles/outer-wall-forksheet-bridge-nanosheet-and-cfet-device-architectures-logic-technology">https://www.imec-int.com/en/articles/outer-wall-forksheet-bridge-nanosheet-and-cfet-device-architectures-logic-technology</a>. [Accessed: Dec. 07, 2025]</div>
</div>
<div id="ref-Hossen2020PowerDN" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">M. O. Hossen, B. Chava, G. van der Plas, E. Beyne, and M. S. Bakir, <span>“Power delivery network (PDN) modeling for backside-PDN configurations with buried power rails and $$ TSVs,”</span> <em>IEEE Transactions on Electron Devices</em>, vol. 67, pp. 11–17, 2020, Available: <a href="https://api.semanticscholar.org/CorpusID:209853271">https://api.semanticscholar.org/CorpusID:209853271</a></div>
</div>
<div id="ref-filho_2024_what" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">R. P. Filho, <span>“What is a chiplet, and why should you care?”</span> Keysight.com, Aug. 2024. Available: <a href="https://www.keysight.com/blogs/en/tech/sim-des/what-is-a-chiplet-and-why-should-you-care">https://www.keysight.com/blogs/en/tech/sim-des/what-is-a-chiplet-and-why-should-you-care</a>. [Accessed: Nov. 16, 2025]</div>
</div>
<div id="ref-zhao2024analyticalheterogeneousdietodie3d" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">Y. Zhao, P. Liao, S. Liu, J. Jiang, Y. Lin, and B. Yu, <span>“Analytical heterogeneous die-to-die 3D placement with macros.”</span> 2024. Available: <a href="https://arxiv.org/abs/2403.09070">https://arxiv.org/abs/2403.09070</a></div>
</div>
<div id="ref-10454441" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">A. Smith <em>et al.</em>, <span>“11.1 AMD InstinctTM MI300 series modular chiplet package – HPC and AI accelerator for exa-class systems,”</span> in <em>2024 IEEE international solid-state circuits conference (ISSCC)</em>, 2024, pp. 490–492. doi: <a href="https://doi.org/10.1109/ISSCC49657.2024.10454441">10.1109/ISSCC49657.2024.10454441</a></div>
</div>
<div id="ref-phdthesisAlgorithms2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">J. Monteiro, <span>“Algorithms to improve area density utilization, routability and timing during detailed placement and legalization of VLSI circuits,”</span> PhD thesis, 2019.</div>
</div>
<div id="ref-mellor2021neuralarchitecturesearchtraining" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">J. Mellor, J. Turner, A. Storkey, and E. J. Crowley, <span>“Neural architecture search without training.”</span> 2021. Available: <a href="https://arxiv.org/abs/2006.04647">https://arxiv.org/abs/2006.04647</a></div>
</div>
<div id="ref-deng2025edgeintelligencespikingneural" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">S. Deng <em>et al.</em>, <span>“Edge intelligence with spiking neural networks.”</span> 2025. Available: <a href="https://arxiv.org/abs/2507.14069">https://arxiv.org/abs/2507.14069</a></div>
</div>
<div id="ref-somvanshi2025tinymachinelearningtiny" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">S. Somvanshi <em>et al.</em>, <span>“From tiny machine learning to tiny deep learning: A survey.”</span> 2025. Available: <a href="https://arxiv.org/abs/2506.18927">https://arxiv.org/abs/2506.18927</a></div>
</div>
<div id="ref-tcheyan_2025_decentralized" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">L. Tcheyan and A. Yenamandra, <span>“Decentralized AI training: Architectures, opportunities, and challenges.”</span> Galaxy, Sep. 2025. Available: <a href="https://www.galaxy.com/insights/research/decentralized-ai-training">https://www.galaxy.com/insights/research/decentralized-ai-training</a>. [Accessed: Jan. 01, 2026]</div>
</div>
<div id="ref-a2023_understanding" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline"><span>“Understanding memory formats.”</span> Intel, 2023. Available: <a href="https://www.intel.com/content/www/us/en/docs/onednn/developer-guide-reference/2023-1/understanding-memory-formats.html">https://www.intel.com/content/www/us/en/docs/onednn/developer-guide-reference/2023-1/understanding-memory-formats.html</a>. [Accessed: Jan. 03, 2026]</div>
</div>
<div id="ref-anello_2022_visualizing" class="csl-entry" role="listitem">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">E. Anello, <span>“Visualizing the feature maps and filters by convolutional neural networks.”</span> DataSeries, Mar. 2022. Available: <a href="https://medium.com/dataseries/visualizing-the-feature-maps-and-filters-by-convolutional-neural-networks-e1462340518e">https://medium.com/dataseries/visualizing-the-feature-maps-and-filters-by-convolutional-neural-networks-e1462340518e</a>. [Accessed: Jan. 03, 2026]</div>
</div>
<div id="ref-dong2025singleaiclustersurvey" class="csl-entry" role="listitem">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline">H. Dong <em>et al.</em>, <span>“Beyond a single AI cluster: A survey of decentralized LLM training.”</span> 2025. Available: <a href="https://arxiv.org/abs/2503.11023">https://arxiv.org/abs/2503.11023</a></div>
</div>
<div id="ref-_2025_introducing" class="csl-entry" role="listitem">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">Manveer, Matthew, Jannik, and Vincent, <span>“Introducing prime intellect’s protocol &amp; testnet: A peer-to-peer compute and intelligence network.”</span> Primeintellect.ai, Feb. 2025. Available: <a href="https://www.primeintellect.ai/blog/protocol">https://www.primeintellect.ai/blog/protocol</a>. [Accessed: Jan. 01, 2026]</div>
</div>
<div id="ref-_2025_chakra" class="csl-entry" role="listitem">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline">Chakra Team, <span>“Chakra labs.”</span> Chakra.dev, Jun. 2025. Available: <a href="https://www.chakra.dev/research/the-third-epoch-of-ai-decentralizing-the-training-stack">https://www.chakra.dev/research/the-third-epoch-of-ai-decentralizing-the-training-stack</a>. [Accessed: Jan. 01, 2026]</div>
</div>
<div id="ref-sabih2025hardwaresoftwarecodesignriscvextensions" class="csl-entry" role="listitem">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">M. Sabih, A. Karim, J. Wittmann, F. Hannig, and J. Teich, <span>“Hardware/software co-design of RISC-v extensions for accelerating sparse DNNs on FPGAs.”</span> 2025. Available: <a href="https://arxiv.org/abs/2504.19659">https://arxiv.org/abs/2504.19659</a></div>
</div>
<div id="ref-skki_2025_quantization" class="csl-entry" role="listitem">
<div class="csl-left-margin">[22] </div><div class="csl-right-inline">SKki, <span>“Quantization methods explanation.”</span> Bilibili.com, Jun. 2025. Available: <a href="https://www.bilibili.com/video/BV1iyNmzxECP/?spm_id_from=333.1391.0.0&amp;vd_source=42579e22289b6144ba0b2bdcf99834e3">https://www.bilibili.com/video/BV1iyNmzxECP/?spm_id_from=333.1391.0.0&amp;vd_source=42579e22289b6144ba0b2bdcf99834e3</a>. [Accessed: Jan. 03, 2026]</div>
</div>
<div id="ref-maciejbalawejder_2022_optimizers" class="csl-entry" role="listitem">
<div class="csl-left-margin">[23] </div><div class="csl-right-inline">M. Balawejder, <span>“Optimizers in machine learning - nerd for tech - medium.”</span> Medium; Nerd for Tech, Mar. 2022. Available: <a href="https://medium.com/nerd-for-tech/optimizers-in-machine-learning-f1a9c549f8b4">https://medium.com/nerd-for-tech/optimizers-in-machine-learning-f1a9c549f8b4</a>. [Accessed: Dec. 05, 2025]</div>
</div>
<div id="ref-tg_2020_why" class="csl-entry" role="listitem">
<div class="csl-left-margin">[24] </div><div class="csl-right-inline">J. TG, <span>“Why sparse features should have bigger learning rates associated? And how adagrad achieves this?”</span> Data Science Stack Exchange, Sep. 2020. Available: <a href="https://datascience.stackexchange.com/questions/82240/why-sparse-features-should-have-bigger-learning-rates-associated-and-how-adagra">https://datascience.stackexchange.com/questions/82240/why-sparse-features-should-have-bigger-learning-rates-associated-and-how-adagra</a>. [Accessed: Dec. 03, 2025]</div>
</div>
<div id="ref-The_Human_Developers_2025_cnblogs" class="csl-entry" role="listitem">
<div class="csl-left-margin">[25] </div><div class="csl-right-inline">S. Dai, <span>“Symbol grounding problem in artificial intelligence,”</span> 2025, Available: <a href="https://www.cnblogs.com/sddai/p/18670953">https://www.cnblogs.com/sddai/p/18670953</a></div>
</div>
<div id="ref-battaglia2018relationalinductivebiasesdeep" class="csl-entry" role="listitem">
<div class="csl-left-margin">[26] </div><div class="csl-right-inline">P. W. Battaglia <em>et al.</em>, <span>“Relational inductive biases, deep learning, and graph networks.”</span> 2018. Available: <a href="https://arxiv.org/abs/1806.01261">https://arxiv.org/abs/1806.01261</a></div>
</div>
<div id="ref-juliaturc_2025_why" class="csl-entry" role="listitem">
<div class="csl-left-margin">[27] </div><div class="csl-right-inline">J. Turc, <span>“Why are transformers replacing CNNs?”</span> YouTube, Dec. 2025. Available: <a href="https://www.youtube.com/watch?v=KnCRTP11p5U">https://www.youtube.com/watch?v=KnCRTP11p5U</a>. [Accessed: Jan. 07, 2026]</div>
</div>
<div id="ref-gerstnerlab_2023_rl36" class="csl-entry" role="listitem">
<div class="csl-left-margin">[28] </div><div class="csl-right-inline">G. Lab, <span>“RL3.6 inductive bias in machine learning.”</span> YouTube, Mar. 2023. Available: <a href="https://www.youtube.com/watch?v=FhBMOqyMjYw">https://www.youtube.com/watch?v=FhBMOqyMjYw</a>. [Accessed: Jan. 07, 2026]</div>
</div>
<div id="ref-Lazyparser_2025_bilibili" class="csl-entry" role="listitem">
<div class="csl-left-margin">[29] </div><div class="csl-right-inline">Lazyparser, <span>“Compilation and linker,”</span> 2025, Available: <a href="https://www.bilibili.com/video/BV1Q5411w7z5?spm_id_from=333.788.videopod.episodes&amp;vd_source=42579e22289b6144ba0b2bdcf99834e3&amp;p=5">https://www.bilibili.com/video/BV1Q5411w7z5?spm_id_from=333.788.videopod.episodes&amp;vd_source=42579e22289b6144ba0b2bdcf99834e3&amp;p=5</a></div>
</div>
<div id="ref-googlecoral_2025_github" class="csl-entry" role="listitem">
<div class="csl-left-margin">[30] </div><div class="csl-right-inline">google-coral, <span>“GitHub - google-coral/coralnpu: A machine learning accelerator core designed for energy-efficient AI at the edge.”</span> GitHub, Oct. 2025. Available: <a href="https://github.com/google-coral/coralnpu">https://github.com/google-coral/coralnpu</a>. [Accessed: Jan. 04, 2026]</div>
</div>
</div>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../resources/resources.html" class="pagination-link" aria-label="Resources 学习资料汇总">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Resources 学习资料汇总</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../research-proposal/research-proposal.html" class="pagination-link" aria-label="Research Proposal: New Inference Paradigms for ML at the Edge">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Research Proposal: New Inference Paradigms for ML at the Edge</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>